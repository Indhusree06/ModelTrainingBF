{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "rzTF-AZHGBWR",
        "outputId": "14f0287b-1541-46fe-e5e4-a08abf98a4c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '_name_' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-50ee2209e5c3>\u001b[0m in \u001b[0;36m<cell line: 103>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0m_name_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"_main_\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m     \u001b[0;31m# Set device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_name_' is not defined"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision numpy tqdm\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "\n",
        "class CustomFashionMNIST(Dataset):\n",
        "    def _init_(self, root='./data', train=True, transform=None):\n",
        "        self.original_dataset = datasets.FashionMNIST(\n",
        "            root=root,\n",
        "            train=train,\n",
        "            download=True\n",
        "        )\n",
        "\n",
        "        self.data = self.original_dataset.data.numpy()\n",
        "        self.targets = self.original_dataset.targets.numpy()\n",
        "        self.data = self.data.astype(np.float32) / 255.0\n",
        "        self.transform = transform\n",
        "\n",
        "        self.classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "                       'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "    def _len_(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _getitem_(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.targets[idx]\n",
        "        image = torch.FloatTensor(image).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class FashionNet(nn.Module):\n",
        "    def _init_(self):\n",
        "        super(FashionNet, self)._init_()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def save_model(model, optimizer, epoch, accuracy, is_best=False):\n",
        "    \"\"\"Save model weights - both best and last\"\"\"\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'accuracy': accuracy\n",
        "    }\n",
        "\n",
        "    # Always save the last model\n",
        "    last_filename = 'fashion_model_last.pt'\n",
        "    torch.save(checkpoint, last_filename)  # Removed weights_only parameter\n",
        "    print(f\"Last model saved to {last_filename}\")\n",
        "\n",
        "    # Save best model separately if it's the best\n",
        "    if is_best:\n",
        "        best_filename = 'fashion_model_best.pt'\n",
        "        torch.save(checkpoint, best_filename)  # Removed weights_only parameter\n",
        "        print(f\"Best model saved to {best_filename}\")\n",
        "\n",
        "def load_model(filename='fashion_model_best.pt'):\n",
        "    \"\"\"Load model weights\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = FashionNet().to(device)\n",
        "\n",
        "    try:\n",
        "        checkpoint = torch.load(filename, map_location=device)  # Removed weights_only parameter\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        accuracy = checkpoint.get('accuracy', 0.0)\n",
        "        epoch = checkpoint.get('epoch', 0)\n",
        "        print(f\"Model loaded from {filename}\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "        return model, accuracy, epoch\n",
        "    except FileNotFoundError:\n",
        "        print(f\"No saved model found at {filename}\")\n",
        "        return model, 0.0, 0\n",
        "\n",
        "if _name_ == \"_main_\":\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_dataset = CustomFashionMNIST(train=True)\n",
        "    test_dataset = CustomFashionMNIST(train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Create model\n",
        "    model = FashionNet().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train for 100 epochs\n",
        "    num_epochs = 100\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                outputs = model(data)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch: {epoch}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "        # Save both best and last models\n",
        "        is_best = accuracy > best_accuracy\n",
        "        if is_best:\n",
        "            best_accuracy = accuracy\n",
        "            print(f'New best accuracy: {accuracy:.2f}%')\n",
        "        save_model(model, optimizer, epoch, accuracy, is_best=is_best)\n",
        "\n",
        "    print(f\"\\nTraining completed!\")\n",
        "    print(f\"Best accuracy achieved: {best_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "\n",
        "class CustomFashionMNIST(Dataset):\n",
        "    def _init_(self, root='./data', train=True, transform=None):\n",
        "        self.original_dataset = datasets.FashionMNIST(\n",
        "            root=root,\n",
        "            train=train,\n",
        "            download=True\n",
        "        )\n",
        "\n",
        "        self.data = self.original_dataset.data.numpy()\n",
        "        self.targets = self.original_dataset.targets.numpy()\n",
        "        self.data = self.data.astype(np.float32) / 255.0\n",
        "        self.transform = transform\n",
        "\n",
        "        self.classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "                       'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "    def _len_(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _getitem_(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.targets[idx]\n",
        "        image = torch.FloatTensor(image).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class FashionNet(nn.Module):\n",
        "    def _init_(self):\n",
        "        super(FashionNet, self)._init_()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def save_model(model, optimizer, epoch, accuracy, is_best=False):\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'accuracy': accuracy\n",
        "    }\n",
        "\n",
        "\n",
        "    last_filename = 'fashion_model_last.pt'\n",
        "    torch.save(checkpoint, last_filename)\n",
        "    print(f\"Last model saved to {last_filename}\")\n",
        "\n",
        "\n",
        "    if is_best:\n",
        "        best_filename = 'fashion_model_best.pt'\n",
        "        torch.save(checkpoint, best_filename)\n",
        "        print(f\"Best model saved to {best_filename}\")\n",
        "\n",
        "def load_model(filename='fashion_model_best.pt'):\n",
        "    \"\"\"Load model weights\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = FashionNet().to(device)\n",
        "\n",
        "    try:\n",
        "        checkpoint = torch.load(filename, map_location=device)  # Removed weights_only parameter\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        accuracy = checkpoint.get('accuracy', 0.0)\n",
        "        epoch = checkpoint.get('epoch', 0)\n",
        "        print(f\"Model loaded from {filename}\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "        return model, accuracy, epoch\n",
        "    except FileNotFoundError:\n",
        "        print(f\"No saved model found at {filename}\")\n",
        "        return model, 0.0, 0\n",
        "\n",
        "if _name_ == \"_main_\":\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_dataset = CustomFashionMNIST(train=True)\n",
        "    test_dataset = CustomFashionMNIST(train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Create model\n",
        "    model = FashionNet().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train for 100 epochs\n",
        "    num_epochs = 100\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                outputs = model(data)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch: {epoch}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "        # Save both best and last models\n",
        "        is_best = accuracy > best_accuracy\n",
        "        if is_best:\n",
        "            best_accuracy = accuracy\n",
        "            print(f'New best accuracy: {accuracy:.2f}%')\n",
        "        save_model(model, optimizer, epoch, accuracy, is_best=is_best)\n",
        "\n",
        "    print(f\"\\nTraining completed!\")\n",
        "    print(f\"Best accuracy achieved: {best_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "YyA6c2dAHSVr",
        "outputId": "4a1ad2fe-81f7-4251-88e9-2176bbd6b25e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '_name_' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d5333f2470fa>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0m_name_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"_main_\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Set device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_name_' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "\n",
        "class CustomFashionMNIST(Dataset):\n",
        "    def _init_(self, root='./data', train=True, transform=None):\n",
        "        self.original_dataset = datasets.FashionMNIST(\n",
        "            root=root,\n",
        "            train=train,\n",
        "            download=True\n",
        "        )\n",
        "\n",
        "        self.data = self.original_dataset.data.numpy()\n",
        "        self.targets = self.original_dataset.targets.numpy()\n",
        "        self.data = self.data.astype(np.float32) / 255.0\n",
        "        self.transform = transform\n",
        "\n",
        "        self.classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "                       'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "    def _len_(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _getitem_(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.targets[idx]\n",
        "        image = torch.FloatTensor(image).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class FashionNet(nn.Module):\n",
        "    def _init_(self):\n",
        "        super(FashionNet, self)._init_()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def save_model(model, optimizer, epoch, accuracy, is_best=False):\n",
        "\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'accuracy': accuracy\n",
        "    }\n",
        "\n",
        "\n",
        "    last_filename = 'fashion_model_last.pt'\n",
        "    torch.save(checkpoint, last_filename)\n",
        "    print(f\"Last model saved to {last_filename}\")\n",
        "\n",
        "\n",
        "    if is_best:\n",
        "        best_filename = 'fashion_model_best.pt'\n",
        "        torch.save(checkpoint, best_filename)\n",
        "        print(f\"Best model saved to {best_filename}\")\n",
        "\n",
        "def load_model(filename='fashion_model_best.pt'):\n",
        "    \"\"\"Load model weights\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = FashionNet().to(device)\n",
        "\n",
        "    try:\n",
        "        checkpoint = torch.load(filename, map_location=device)  # Removed weights_only parameter\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        accuracy = checkpoint.get('accuracy', 0.0)\n",
        "        epoch = checkpoint.get('epoch', 0)\n",
        "        print(f\"Model loaded from {filename}\")\n",
        "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "        return model, accuracy, epoch\n",
        "    except FileNotFoundError:\n",
        "        print(f\"No saved model found at {filename}\")\n",
        "        return model, 0.0, 0\n",
        "\n",
        "if _name_ == \"_main_\":\n",
        "    # Set device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Create datasets and loaders\n",
        "    train_dataset = CustomFashionMNIST(train=True)\n",
        "    test_dataset = CustomFashionMNIST(train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Create model\n",
        "    model = FashionNet().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Train for 35 epochs\n",
        "    num_epochs = 35\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        model.train()\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        # Evaluation\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                outputs = model(data)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch: {epoch}, Accuracy: {accuracy:.2f}%')\n",
        "\n",
        "        # Save both best and last models\n",
        "        is_best = accuracy > best_accuracy\n",
        "        if is_best:\n",
        "            best_accuracy = accuracy\n",
        "            print(f'New best accuracy: {accuracy:.2f}%')\n",
        "        save_model(model, optimizer, epoch, accuracy, is_best=is_best)\n",
        "\n",
        "    print(f\"\\nTraining completed!\")\n",
        "    print(f\"Best accuracy achieved: {best_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "zhtG6pmQHZch",
        "outputId": "8851a51b-fecc-4a70-986b-a42cf6d0f82a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name '_name_' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e0ce21b9f20e>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0m_name_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"_main_\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;31m# Set device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name '_name_' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, path='./data', is_train=True, transform=None):\n",
        "        self.dataset = datasets.FashionMNIST(\n",
        "            root=path,\n",
        "            train=is_train,\n",
        "            download=True\n",
        "        )\n",
        "\n",
        "        self.images = self.dataset.data.numpy()\n",
        "        self.labels = self.dataset.targets.numpy()\n",
        "        self.images = self.images.astype(np.float32) / 255.0\n",
        "        self.transform = transform\n",
        "\n",
        "        self.class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "                            'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = torch.FloatTensor(image).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "class ConvolutionalNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvolutionalNet, self).__init__()\n",
        "        # Defining layers\n",
        "        self.conv_layer1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "        self.conv_layer2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
        "        self.conv_layer3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(64)\n",
        "\n",
        "        self.pooling_layer = nn.MaxPool2d(2, 2)\n",
        "        self.fc_layer1 = nn.Linear(64 * 7 * 7, 512)\n",
        "        self.dropout_layer = nn.Dropout(0.5)\n",
        "        self.fc_layer2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pooling_layer(F.relu(self.batch_norm1(self.conv_layer1(x))))\n",
        "        x = self.pooling_layer(F.relu(self.batch_norm2(self.conv_layer2(x))))\n",
        "        x = F.relu(self.batch_norm3(self.conv_layer3(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc_layer1(x))\n",
        "        x = self.dropout_layer(x)\n",
        "        x = self.fc_layer2(x)\n",
        "        return x\n",
        "\n",
        "def save_best_model(model, filepath='best_model.pt'):\n",
        "\n",
        "    torch.save(model.state_dict(), filepath)\n",
        "    print(f\"Best model saved as {filepath}\")\n",
        "\n",
        "def load_best_model(filepath='best_model.pt'):\n",
        "    \"\"\"Load the best model's weights\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = ConvolutionalNet().to(device)\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(filepath, map_location=device))\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "        return model\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Model file {filepath} not found.\")\n",
        "        return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Training started on device: {device}\")\n",
        "    train_dataset = ImageDataset(is_train=True)\n",
        "    test_dataset = ImageDataset(is_train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "    model = ConvolutionalNet().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    total_epochs = 85\n",
        "    highest_accuracy = 0.0\n",
        "    best_model_path = 'best_model.pt'\n",
        "\n",
        "    print(\"Training process initiated...\")\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "\n",
        "        model.train()\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss = loss_function(predictions, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f\"Epoch {epoch}, Batch {batch_idx}: Current Loss = {loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                predictions = model(inputs)\n",
        "                _, predicted_labels = torch.max(predictions.data, 1)\n",
        "                total_samples += targets.size(0)\n",
        "                correct_predictions += (predicted_labels == targets).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct_predictions / total_samples\n",
        "        print(f\"Epoch {epoch}, Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        if accuracy > highest_accuracy:\n",
        "            highest_accuracy = accuracy\n",
        "            print(f\"New best accuracy: {accuracy:.2f}%\")\n",
        "            save_best_model(model, best_model_path)\n",
        "\n",
        "    print(f\"\\nTraining complete!\")\n",
        "    print(f\"Highest accuracy achieved during training: {highest_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Khw5X66aS-i",
        "outputId": "a4dcb8d0-6c36-4123-fb52-159225321329"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started on device: cuda\n",
            "Training process initiated...\n",
            "Epoch 0, Batch 0: Current Loss = 2.3439\n",
            "Epoch 0, Batch 100: Current Loss = 0.3413\n",
            "Epoch 0, Batch 200: Current Loss = 0.3487\n",
            "Epoch 0, Batch 300: Current Loss = 0.4281\n",
            "Epoch 0, Batch 400: Current Loss = 0.2316\n",
            "Epoch 0, Batch 500: Current Loss = 0.3792\n",
            "Epoch 0, Batch 600: Current Loss = 0.2449\n",
            "Epoch 0, Batch 700: Current Loss = 0.2986\n",
            "Epoch 0, Batch 800: Current Loss = 0.4399\n",
            "Epoch 0, Batch 900: Current Loss = 0.5002\n",
            "Epoch 0, Test Accuracy: 88.94%\n",
            "New best accuracy: 88.94%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 1, Batch 0: Current Loss = 0.2979\n",
            "Epoch 1, Batch 100: Current Loss = 0.2503\n",
            "Epoch 1, Batch 200: Current Loss = 0.2062\n",
            "Epoch 1, Batch 300: Current Loss = 0.1596\n",
            "Epoch 1, Batch 400: Current Loss = 0.3097\n",
            "Epoch 1, Batch 500: Current Loss = 0.3151\n",
            "Epoch 1, Batch 600: Current Loss = 0.1686\n",
            "Epoch 1, Batch 700: Current Loss = 0.2702\n",
            "Epoch 1, Batch 800: Current Loss = 0.3540\n",
            "Epoch 1, Batch 900: Current Loss = 0.2925\n",
            "Epoch 1, Test Accuracy: 90.69%\n",
            "New best accuracy: 90.69%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 2, Batch 0: Current Loss = 0.1338\n",
            "Epoch 2, Batch 100: Current Loss = 0.1842\n",
            "Epoch 2, Batch 200: Current Loss = 0.2048\n",
            "Epoch 2, Batch 300: Current Loss = 0.3126\n",
            "Epoch 2, Batch 400: Current Loss = 0.2515\n",
            "Epoch 2, Batch 500: Current Loss = 0.2457\n",
            "Epoch 2, Batch 600: Current Loss = 0.1948\n",
            "Epoch 2, Batch 700: Current Loss = 0.2394\n",
            "Epoch 2, Batch 800: Current Loss = 0.3077\n",
            "Epoch 2, Batch 900: Current Loss = 0.1015\n",
            "Epoch 2, Test Accuracy: 91.33%\n",
            "New best accuracy: 91.33%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 3, Batch 0: Current Loss = 0.2001\n",
            "Epoch 3, Batch 100: Current Loss = 0.1215\n",
            "Epoch 3, Batch 200: Current Loss = 0.1669\n",
            "Epoch 3, Batch 300: Current Loss = 0.1605\n",
            "Epoch 3, Batch 400: Current Loss = 0.1839\n",
            "Epoch 3, Batch 500: Current Loss = 0.2553\n",
            "Epoch 3, Batch 600: Current Loss = 0.1744\n",
            "Epoch 3, Batch 700: Current Loss = 0.1895\n",
            "Epoch 3, Batch 800: Current Loss = 0.2669\n",
            "Epoch 3, Batch 900: Current Loss = 0.2836\n",
            "Epoch 3, Test Accuracy: 91.39%\n",
            "New best accuracy: 91.39%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 4, Batch 0: Current Loss = 0.1158\n",
            "Epoch 4, Batch 100: Current Loss = 0.1183\n",
            "Epoch 4, Batch 200: Current Loss = 0.1276\n",
            "Epoch 4, Batch 300: Current Loss = 0.1014\n",
            "Epoch 4, Batch 400: Current Loss = 0.0917\n",
            "Epoch 4, Batch 500: Current Loss = 0.0455\n",
            "Epoch 4, Batch 600: Current Loss = 0.1409\n",
            "Epoch 4, Batch 700: Current Loss = 0.3215\n",
            "Epoch 4, Batch 800: Current Loss = 0.1391\n",
            "Epoch 4, Batch 900: Current Loss = 0.0871\n",
            "Epoch 4, Test Accuracy: 88.83%\n",
            "Epoch 5, Batch 0: Current Loss = 0.3324\n",
            "Epoch 5, Batch 100: Current Loss = 0.1536\n",
            "Epoch 5, Batch 200: Current Loss = 0.1525\n",
            "Epoch 5, Batch 300: Current Loss = 0.0986\n",
            "Epoch 5, Batch 400: Current Loss = 0.1869\n",
            "Epoch 5, Batch 500: Current Loss = 0.3023\n",
            "Epoch 5, Batch 600: Current Loss = 0.1278\n",
            "Epoch 5, Batch 700: Current Loss = 0.0591\n",
            "Epoch 5, Batch 800: Current Loss = 0.1266\n",
            "Epoch 5, Batch 900: Current Loss = 0.2146\n",
            "Epoch 5, Test Accuracy: 92.48%\n",
            "New best accuracy: 92.48%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 6, Batch 0: Current Loss = 0.1437\n",
            "Epoch 6, Batch 100: Current Loss = 0.1928\n",
            "Epoch 6, Batch 200: Current Loss = 0.0968\n",
            "Epoch 6, Batch 300: Current Loss = 0.1384\n",
            "Epoch 6, Batch 400: Current Loss = 0.0769\n",
            "Epoch 6, Batch 500: Current Loss = 0.1085\n",
            "Epoch 6, Batch 600: Current Loss = 0.3350\n",
            "Epoch 6, Batch 700: Current Loss = 0.0599\n",
            "Epoch 6, Batch 800: Current Loss = 0.2522\n",
            "Epoch 6, Batch 900: Current Loss = 0.1894\n",
            "Epoch 6, Test Accuracy: 92.41%\n",
            "Epoch 7, Batch 0: Current Loss = 0.0472\n",
            "Epoch 7, Batch 100: Current Loss = 0.2648\n",
            "Epoch 7, Batch 200: Current Loss = 0.2031\n",
            "Epoch 7, Batch 300: Current Loss = 0.0621\n",
            "Epoch 7, Batch 400: Current Loss = 0.1750\n",
            "Epoch 7, Batch 500: Current Loss = 0.1186\n",
            "Epoch 7, Batch 600: Current Loss = 0.0197\n",
            "Epoch 7, Batch 700: Current Loss = 0.0415\n",
            "Epoch 7, Batch 800: Current Loss = 0.0941\n",
            "Epoch 7, Batch 900: Current Loss = 0.1260\n",
            "Epoch 7, Test Accuracy: 91.80%\n",
            "Epoch 8, Batch 0: Current Loss = 0.0742\n",
            "Epoch 8, Batch 100: Current Loss = 0.1035\n",
            "Epoch 8, Batch 200: Current Loss = 0.0698\n",
            "Epoch 8, Batch 300: Current Loss = 0.1481\n",
            "Epoch 8, Batch 400: Current Loss = 0.1182\n",
            "Epoch 8, Batch 500: Current Loss = 0.1391\n",
            "Epoch 8, Batch 600: Current Loss = 0.0889\n",
            "Epoch 8, Batch 700: Current Loss = 0.0782\n",
            "Epoch 8, Batch 800: Current Loss = 0.0389\n",
            "Epoch 8, Batch 900: Current Loss = 0.0534\n",
            "Epoch 8, Test Accuracy: 92.39%\n",
            "Epoch 9, Batch 0: Current Loss = 0.0117\n",
            "Epoch 9, Batch 100: Current Loss = 0.1506\n",
            "Epoch 9, Batch 200: Current Loss = 0.0271\n",
            "Epoch 9, Batch 300: Current Loss = 0.0813\n",
            "Epoch 9, Batch 400: Current Loss = 0.0378\n",
            "Epoch 9, Batch 500: Current Loss = 0.0911\n",
            "Epoch 9, Batch 600: Current Loss = 0.0922\n",
            "Epoch 9, Batch 700: Current Loss = 0.0772\n",
            "Epoch 9, Batch 800: Current Loss = 0.1470\n",
            "Epoch 9, Batch 900: Current Loss = 0.1847\n",
            "Epoch 9, Test Accuracy: 92.54%\n",
            "New best accuracy: 92.54%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 10, Batch 0: Current Loss = 0.1315\n",
            "Epoch 10, Batch 100: Current Loss = 0.0904\n",
            "Epoch 10, Batch 200: Current Loss = 0.0743\n",
            "Epoch 10, Batch 300: Current Loss = 0.0321\n",
            "Epoch 10, Batch 400: Current Loss = 0.0986\n",
            "Epoch 10, Batch 500: Current Loss = 0.0734\n",
            "Epoch 10, Batch 600: Current Loss = 0.0801\n",
            "Epoch 10, Batch 700: Current Loss = 0.1737\n",
            "Epoch 10, Batch 800: Current Loss = 0.0669\n",
            "Epoch 10, Batch 900: Current Loss = 0.0931\n",
            "Epoch 10, Test Accuracy: 92.50%\n",
            "Epoch 11, Batch 0: Current Loss = 0.0237\n",
            "Epoch 11, Batch 100: Current Loss = 0.0734\n",
            "Epoch 11, Batch 200: Current Loss = 0.0810\n",
            "Epoch 11, Batch 300: Current Loss = 0.0805\n",
            "Epoch 11, Batch 400: Current Loss = 0.0931\n",
            "Epoch 11, Batch 500: Current Loss = 0.0902\n",
            "Epoch 11, Batch 600: Current Loss = 0.0620\n",
            "Epoch 11, Batch 700: Current Loss = 0.0678\n",
            "Epoch 11, Batch 800: Current Loss = 0.0457\n",
            "Epoch 11, Batch 900: Current Loss = 0.0513\n",
            "Epoch 11, Test Accuracy: 92.05%\n",
            "Epoch 12, Batch 0: Current Loss = 0.0179\n",
            "Epoch 12, Batch 100: Current Loss = 0.0357\n",
            "Epoch 12, Batch 200: Current Loss = 0.0336\n",
            "Epoch 12, Batch 300: Current Loss = 0.0619\n",
            "Epoch 12, Batch 400: Current Loss = 0.0295\n",
            "Epoch 12, Batch 500: Current Loss = 0.0449\n",
            "Epoch 12, Batch 600: Current Loss = 0.0245\n",
            "Epoch 12, Batch 700: Current Loss = 0.0495\n",
            "Epoch 12, Batch 800: Current Loss = 0.0434\n",
            "Epoch 12, Batch 900: Current Loss = 0.0182\n",
            "Epoch 12, Test Accuracy: 92.47%\n",
            "Epoch 13, Batch 0: Current Loss = 0.0946\n",
            "Epoch 13, Batch 100: Current Loss = 0.0117\n",
            "Epoch 13, Batch 200: Current Loss = 0.0456\n",
            "Epoch 13, Batch 300: Current Loss = 0.1025\n",
            "Epoch 13, Batch 400: Current Loss = 0.0144\n",
            "Epoch 13, Batch 500: Current Loss = 0.0053\n",
            "Epoch 13, Batch 600: Current Loss = 0.0920\n",
            "Epoch 13, Batch 700: Current Loss = 0.0387\n",
            "Epoch 13, Batch 800: Current Loss = 0.0576\n",
            "Epoch 13, Batch 900: Current Loss = 0.0864\n",
            "Epoch 13, Test Accuracy: 92.58%\n",
            "New best accuracy: 92.58%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 14, Batch 0: Current Loss = 0.0461\n",
            "Epoch 14, Batch 100: Current Loss = 0.0412\n",
            "Epoch 14, Batch 200: Current Loss = 0.0334\n",
            "Epoch 14, Batch 300: Current Loss = 0.0731\n",
            "Epoch 14, Batch 400: Current Loss = 0.0417\n",
            "Epoch 14, Batch 500: Current Loss = 0.0476\n",
            "Epoch 14, Batch 600: Current Loss = 0.0175\n",
            "Epoch 14, Batch 700: Current Loss = 0.1291\n",
            "Epoch 14, Batch 800: Current Loss = 0.0405\n",
            "Epoch 14, Batch 900: Current Loss = 0.0268\n",
            "Epoch 14, Test Accuracy: 92.42%\n",
            "Epoch 15, Batch 0: Current Loss = 0.1159\n",
            "Epoch 15, Batch 100: Current Loss = 0.0305\n",
            "Epoch 15, Batch 200: Current Loss = 0.0271\n",
            "Epoch 15, Batch 300: Current Loss = 0.0339\n",
            "Epoch 15, Batch 400: Current Loss = 0.0464\n",
            "Epoch 15, Batch 500: Current Loss = 0.0054\n",
            "Epoch 15, Batch 600: Current Loss = 0.0648\n",
            "Epoch 15, Batch 700: Current Loss = 0.1289\n",
            "Epoch 15, Batch 800: Current Loss = 0.0186\n",
            "Epoch 15, Batch 900: Current Loss = 0.0540\n",
            "Epoch 15, Test Accuracy: 92.68%\n",
            "New best accuracy: 92.68%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 16, Batch 0: Current Loss = 0.0945\n",
            "Epoch 16, Batch 100: Current Loss = 0.0652\n",
            "Epoch 16, Batch 200: Current Loss = 0.0274\n",
            "Epoch 16, Batch 300: Current Loss = 0.0748\n",
            "Epoch 16, Batch 400: Current Loss = 0.0337\n",
            "Epoch 16, Batch 500: Current Loss = 0.0274\n",
            "Epoch 16, Batch 600: Current Loss = 0.0010\n",
            "Epoch 16, Batch 700: Current Loss = 0.0165\n",
            "Epoch 16, Batch 800: Current Loss = 0.0079\n",
            "Epoch 16, Batch 900: Current Loss = 0.0104\n",
            "Epoch 16, Test Accuracy: 92.47%\n",
            "Epoch 17, Batch 0: Current Loss = 0.0516\n",
            "Epoch 17, Batch 100: Current Loss = 0.0231\n",
            "Epoch 17, Batch 200: Current Loss = 0.0186\n",
            "Epoch 17, Batch 300: Current Loss = 0.0237\n",
            "Epoch 17, Batch 400: Current Loss = 0.0478\n",
            "Epoch 17, Batch 500: Current Loss = 0.0967\n",
            "Epoch 17, Batch 600: Current Loss = 0.0140\n",
            "Epoch 17, Batch 700: Current Loss = 0.0241\n",
            "Epoch 17, Batch 800: Current Loss = 0.0464\n",
            "Epoch 17, Batch 900: Current Loss = 0.1148\n",
            "Epoch 17, Test Accuracy: 92.79%\n",
            "New best accuracy: 92.79%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 18, Batch 0: Current Loss = 0.0448\n",
            "Epoch 18, Batch 100: Current Loss = 0.0048\n",
            "Epoch 18, Batch 200: Current Loss = 0.0404\n",
            "Epoch 18, Batch 300: Current Loss = 0.0185\n",
            "Epoch 18, Batch 400: Current Loss = 0.0126\n",
            "Epoch 18, Batch 500: Current Loss = 0.0241\n",
            "Epoch 18, Batch 600: Current Loss = 0.1183\n",
            "Epoch 18, Batch 700: Current Loss = 0.0111\n",
            "Epoch 18, Batch 800: Current Loss = 0.0114\n",
            "Epoch 18, Batch 900: Current Loss = 0.0148\n",
            "Epoch 18, Test Accuracy: 92.12%\n",
            "Epoch 19, Batch 0: Current Loss = 0.0708\n",
            "Epoch 19, Batch 100: Current Loss = 0.0259\n",
            "Epoch 19, Batch 200: Current Loss = 0.0797\n",
            "Epoch 19, Batch 300: Current Loss = 0.0050\n",
            "Epoch 19, Batch 400: Current Loss = 0.0497\n",
            "Epoch 19, Batch 500: Current Loss = 0.0071\n",
            "Epoch 19, Batch 600: Current Loss = 0.0932\n",
            "Epoch 19, Batch 700: Current Loss = 0.0860\n",
            "Epoch 19, Batch 800: Current Loss = 0.0679\n",
            "Epoch 19, Batch 900: Current Loss = 0.0391\n",
            "Epoch 19, Test Accuracy: 92.17%\n",
            "Epoch 20, Batch 0: Current Loss = 0.0114\n",
            "Epoch 20, Batch 100: Current Loss = 0.0747\n",
            "Epoch 20, Batch 200: Current Loss = 0.0688\n",
            "Epoch 20, Batch 300: Current Loss = 0.0048\n",
            "Epoch 20, Batch 400: Current Loss = 0.0426\n",
            "Epoch 20, Batch 500: Current Loss = 0.0163\n",
            "Epoch 20, Batch 600: Current Loss = 0.0959\n",
            "Epoch 20, Batch 700: Current Loss = 0.0680\n",
            "Epoch 20, Batch 800: Current Loss = 0.0265\n",
            "Epoch 20, Batch 900: Current Loss = 0.0990\n",
            "Epoch 20, Test Accuracy: 92.09%\n",
            "Epoch 21, Batch 0: Current Loss = 0.0138\n",
            "Epoch 21, Batch 100: Current Loss = 0.0352\n",
            "Epoch 21, Batch 200: Current Loss = 0.0053\n",
            "Epoch 21, Batch 300: Current Loss = 0.0091\n",
            "Epoch 21, Batch 400: Current Loss = 0.0033\n",
            "Epoch 21, Batch 500: Current Loss = 0.0269\n",
            "Epoch 21, Batch 600: Current Loss = 0.0830\n",
            "Epoch 21, Batch 700: Current Loss = 0.0112\n",
            "Epoch 21, Batch 800: Current Loss = 0.0038\n",
            "Epoch 21, Batch 900: Current Loss = 0.0308\n",
            "Epoch 21, Test Accuracy: 92.07%\n",
            "Epoch 22, Batch 0: Current Loss = 0.0235\n",
            "Epoch 22, Batch 100: Current Loss = 0.0803\n",
            "Epoch 22, Batch 200: Current Loss = 0.0036\n",
            "Epoch 22, Batch 300: Current Loss = 0.1649\n",
            "Epoch 22, Batch 400: Current Loss = 0.0235\n",
            "Epoch 22, Batch 500: Current Loss = 0.0406\n",
            "Epoch 22, Batch 600: Current Loss = 0.0051\n",
            "Epoch 22, Batch 700: Current Loss = 0.0036\n",
            "Epoch 22, Batch 800: Current Loss = 0.0098\n",
            "Epoch 22, Batch 900: Current Loss = 0.0046\n",
            "Epoch 22, Test Accuracy: 92.56%\n",
            "Epoch 23, Batch 0: Current Loss = 0.0534\n",
            "Epoch 23, Batch 100: Current Loss = 0.0075\n",
            "Epoch 23, Batch 200: Current Loss = 0.0532\n",
            "Epoch 23, Batch 300: Current Loss = 0.0231\n",
            "Epoch 23, Batch 400: Current Loss = 0.0367\n",
            "Epoch 23, Batch 500: Current Loss = 0.0137\n",
            "Epoch 23, Batch 600: Current Loss = 0.0098\n",
            "Epoch 23, Batch 700: Current Loss = 0.0378\n",
            "Epoch 23, Batch 800: Current Loss = 0.0372\n",
            "Epoch 23, Batch 900: Current Loss = 0.0309\n",
            "Epoch 23, Test Accuracy: 92.17%\n",
            "Epoch 24, Batch 0: Current Loss = 0.0016\n",
            "Epoch 24, Batch 100: Current Loss = 0.0045\n",
            "Epoch 24, Batch 200: Current Loss = 0.0117\n",
            "Epoch 24, Batch 300: Current Loss = 0.0024\n",
            "Epoch 24, Batch 400: Current Loss = 0.0009\n",
            "Epoch 24, Batch 500: Current Loss = 0.0384\n",
            "Epoch 24, Batch 600: Current Loss = 0.0248\n",
            "Epoch 24, Batch 700: Current Loss = 0.0036\n",
            "Epoch 24, Batch 800: Current Loss = 0.0073\n",
            "Epoch 24, Batch 900: Current Loss = 0.0211\n",
            "Epoch 24, Test Accuracy: 92.67%\n",
            "Epoch 25, Batch 0: Current Loss = 0.0527\n",
            "Epoch 25, Batch 100: Current Loss = 0.0578\n",
            "Epoch 25, Batch 200: Current Loss = 0.0016\n",
            "Epoch 25, Batch 300: Current Loss = 0.0003\n",
            "Epoch 25, Batch 400: Current Loss = 0.0324\n",
            "Epoch 25, Batch 500: Current Loss = 0.0053\n",
            "Epoch 25, Batch 600: Current Loss = 0.0195\n",
            "Epoch 25, Batch 700: Current Loss = 0.1073\n",
            "Epoch 25, Batch 800: Current Loss = 0.0326\n",
            "Epoch 25, Batch 900: Current Loss = 0.0253\n",
            "Epoch 25, Test Accuracy: 92.56%\n",
            "Epoch 26, Batch 0: Current Loss = 0.0631\n",
            "Epoch 26, Batch 100: Current Loss = 0.0003\n",
            "Epoch 26, Batch 200: Current Loss = 0.0142\n",
            "Epoch 26, Batch 300: Current Loss = 0.0060\n",
            "Epoch 26, Batch 400: Current Loss = 0.0158\n",
            "Epoch 26, Batch 500: Current Loss = 0.0010\n",
            "Epoch 26, Batch 600: Current Loss = 0.0057\n",
            "Epoch 26, Batch 700: Current Loss = 0.0109\n",
            "Epoch 26, Batch 800: Current Loss = 0.0804\n",
            "Epoch 26, Batch 900: Current Loss = 0.0091\n",
            "Epoch 26, Test Accuracy: 92.42%\n",
            "Epoch 27, Batch 0: Current Loss = 0.0201\n",
            "Epoch 27, Batch 100: Current Loss = 0.0564\n",
            "Epoch 27, Batch 200: Current Loss = 0.0008\n",
            "Epoch 27, Batch 300: Current Loss = 0.0265\n",
            "Epoch 27, Batch 400: Current Loss = 0.0086\n",
            "Epoch 27, Batch 500: Current Loss = 0.0230\n",
            "Epoch 27, Batch 600: Current Loss = 0.0180\n",
            "Epoch 27, Batch 700: Current Loss = 0.0159\n",
            "Epoch 27, Batch 800: Current Loss = 0.0010\n",
            "Epoch 27, Batch 900: Current Loss = 0.0049\n",
            "Epoch 27, Test Accuracy: 92.67%\n",
            "Epoch 28, Batch 0: Current Loss = 0.0545\n",
            "Epoch 28, Batch 100: Current Loss = 0.0305\n",
            "Epoch 28, Batch 200: Current Loss = 0.0303\n",
            "Epoch 28, Batch 300: Current Loss = 0.1419\n",
            "Epoch 28, Batch 400: Current Loss = 0.0054\n",
            "Epoch 28, Batch 500: Current Loss = 0.0566\n",
            "Epoch 28, Batch 600: Current Loss = 0.0409\n",
            "Epoch 28, Batch 700: Current Loss = 0.0164\n",
            "Epoch 28, Batch 800: Current Loss = 0.1592\n",
            "Epoch 28, Batch 900: Current Loss = 0.0022\n",
            "Epoch 28, Test Accuracy: 92.56%\n",
            "Epoch 29, Batch 0: Current Loss = 0.0234\n",
            "Epoch 29, Batch 100: Current Loss = 0.0397\n",
            "Epoch 29, Batch 200: Current Loss = 0.0356\n",
            "Epoch 29, Batch 300: Current Loss = 0.0281\n",
            "Epoch 29, Batch 400: Current Loss = 0.0010\n",
            "Epoch 29, Batch 500: Current Loss = 0.0059\n",
            "Epoch 29, Batch 600: Current Loss = 0.0403\n",
            "Epoch 29, Batch 700: Current Loss = 0.0860\n",
            "Epoch 29, Batch 800: Current Loss = 0.0192\n",
            "Epoch 29, Batch 900: Current Loss = 0.0158\n",
            "Epoch 29, Test Accuracy: 92.43%\n",
            "Epoch 30, Batch 0: Current Loss = 0.0005\n",
            "Epoch 30, Batch 100: Current Loss = 0.0015\n",
            "Epoch 30, Batch 200: Current Loss = 0.0027\n",
            "Epoch 30, Batch 300: Current Loss = 0.0044\n",
            "Epoch 30, Batch 400: Current Loss = 0.0027\n",
            "Epoch 30, Batch 500: Current Loss = 0.0062\n",
            "Epoch 30, Batch 600: Current Loss = 0.0488\n",
            "Epoch 30, Batch 700: Current Loss = 0.0013\n",
            "Epoch 30, Batch 800: Current Loss = 0.0015\n",
            "Epoch 30, Batch 900: Current Loss = 0.0002\n",
            "Epoch 30, Test Accuracy: 91.92%\n",
            "Epoch 31, Batch 0: Current Loss = 0.0149\n",
            "Epoch 31, Batch 100: Current Loss = 0.0319\n",
            "Epoch 31, Batch 200: Current Loss = 0.0178\n",
            "Epoch 31, Batch 300: Current Loss = 0.0015\n",
            "Epoch 31, Batch 400: Current Loss = 0.0199\n",
            "Epoch 31, Batch 500: Current Loss = 0.0299\n",
            "Epoch 31, Batch 600: Current Loss = 0.0493\n",
            "Epoch 31, Batch 700: Current Loss = 0.0163\n",
            "Epoch 31, Batch 800: Current Loss = 0.0600\n",
            "Epoch 31, Batch 900: Current Loss = 0.0051\n",
            "Epoch 31, Test Accuracy: 92.23%\n",
            "Epoch 32, Batch 0: Current Loss = 0.0365\n",
            "Epoch 32, Batch 100: Current Loss = 0.0282\n",
            "Epoch 32, Batch 200: Current Loss = 0.0117\n",
            "Epoch 32, Batch 300: Current Loss = 0.0007\n",
            "Epoch 32, Batch 400: Current Loss = 0.0014\n",
            "Epoch 32, Batch 500: Current Loss = 0.0191\n",
            "Epoch 32, Batch 600: Current Loss = 0.0365\n",
            "Epoch 32, Batch 700: Current Loss = 0.0041\n",
            "Epoch 32, Batch 800: Current Loss = 0.0065\n",
            "Epoch 32, Batch 900: Current Loss = 0.0030\n",
            "Epoch 32, Test Accuracy: 92.50%\n",
            "Epoch 33, Batch 0: Current Loss = 0.0186\n",
            "Epoch 33, Batch 100: Current Loss = 0.1051\n",
            "Epoch 33, Batch 200: Current Loss = 0.0031\n",
            "Epoch 33, Batch 300: Current Loss = 0.0063\n",
            "Epoch 33, Batch 400: Current Loss = 0.0026\n",
            "Epoch 33, Batch 500: Current Loss = 0.0154\n",
            "Epoch 33, Batch 600: Current Loss = 0.0474\n",
            "Epoch 33, Batch 700: Current Loss = 0.0094\n",
            "Epoch 33, Batch 800: Current Loss = 0.0142\n",
            "Epoch 33, Batch 900: Current Loss = 0.0349\n",
            "Epoch 33, Test Accuracy: 92.40%\n",
            "Epoch 34, Batch 0: Current Loss = 0.0098\n",
            "Epoch 34, Batch 100: Current Loss = 0.0071\n",
            "Epoch 34, Batch 200: Current Loss = 0.0063\n",
            "Epoch 34, Batch 300: Current Loss = 0.0619\n",
            "Epoch 34, Batch 400: Current Loss = 0.0015\n",
            "Epoch 34, Batch 500: Current Loss = 0.0111\n",
            "Epoch 34, Batch 600: Current Loss = 0.0328\n",
            "Epoch 34, Batch 700: Current Loss = 0.0030\n",
            "Epoch 34, Batch 800: Current Loss = 0.0035\n",
            "Epoch 34, Batch 900: Current Loss = 0.0228\n",
            "Epoch 34, Test Accuracy: 92.58%\n",
            "Epoch 35, Batch 0: Current Loss = 0.0398\n",
            "Epoch 35, Batch 100: Current Loss = 0.0018\n",
            "Epoch 35, Batch 200: Current Loss = 0.0400\n",
            "Epoch 35, Batch 300: Current Loss = 0.0004\n",
            "Epoch 35, Batch 400: Current Loss = 0.0053\n",
            "Epoch 35, Batch 500: Current Loss = 0.0365\n",
            "Epoch 35, Batch 600: Current Loss = 0.0320\n",
            "Epoch 35, Batch 700: Current Loss = 0.0171\n",
            "Epoch 35, Batch 800: Current Loss = 0.0036\n",
            "Epoch 35, Batch 900: Current Loss = 0.0293\n",
            "Epoch 35, Test Accuracy: 92.24%\n",
            "Epoch 36, Batch 0: Current Loss = 0.0176\n",
            "Epoch 36, Batch 100: Current Loss = 0.0012\n",
            "Epoch 36, Batch 200: Current Loss = 0.0370\n",
            "Epoch 36, Batch 300: Current Loss = 0.0660\n",
            "Epoch 36, Batch 400: Current Loss = 0.0005\n",
            "Epoch 36, Batch 500: Current Loss = 0.0003\n",
            "Epoch 36, Batch 600: Current Loss = 0.0005\n",
            "Epoch 36, Batch 700: Current Loss = 0.0111\n",
            "Epoch 36, Batch 800: Current Loss = 0.0161\n",
            "Epoch 36, Batch 900: Current Loss = 0.0082\n",
            "Epoch 36, Test Accuracy: 92.71%\n",
            "Epoch 37, Batch 0: Current Loss = 0.0298\n",
            "Epoch 37, Batch 100: Current Loss = 0.0002\n",
            "Epoch 37, Batch 200: Current Loss = 0.0089\n",
            "Epoch 37, Batch 300: Current Loss = 0.0037\n",
            "Epoch 37, Batch 400: Current Loss = 0.0000\n",
            "Epoch 37, Batch 500: Current Loss = 0.0014\n",
            "Epoch 37, Batch 600: Current Loss = 0.0023\n",
            "Epoch 37, Batch 700: Current Loss = 0.0472\n",
            "Epoch 37, Batch 800: Current Loss = 0.0044\n",
            "Epoch 37, Batch 900: Current Loss = 0.0450\n",
            "Epoch 37, Test Accuracy: 92.46%\n",
            "Epoch 38, Batch 0: Current Loss = 0.0097\n",
            "Epoch 38, Batch 100: Current Loss = 0.1398\n",
            "Epoch 38, Batch 200: Current Loss = 0.1162\n",
            "Epoch 38, Batch 300: Current Loss = 0.0678\n",
            "Epoch 38, Batch 400: Current Loss = 0.0101\n",
            "Epoch 38, Batch 500: Current Loss = 0.1488\n",
            "Epoch 38, Batch 600: Current Loss = 0.0024\n",
            "Epoch 38, Batch 700: Current Loss = 0.0014\n",
            "Epoch 38, Batch 800: Current Loss = 0.0009\n",
            "Epoch 38, Batch 900: Current Loss = 0.0039\n",
            "Epoch 38, Test Accuracy: 92.34%\n",
            "Epoch 39, Batch 0: Current Loss = 0.0241\n",
            "Epoch 39, Batch 100: Current Loss = 0.0054\n",
            "Epoch 39, Batch 200: Current Loss = 0.0063\n",
            "Epoch 39, Batch 300: Current Loss = 0.0026\n",
            "Epoch 39, Batch 400: Current Loss = 0.0402\n",
            "Epoch 39, Batch 500: Current Loss = 0.0029\n",
            "Epoch 39, Batch 600: Current Loss = 0.0367\n",
            "Epoch 39, Batch 700: Current Loss = 0.0555\n",
            "Epoch 39, Batch 800: Current Loss = 0.0012\n",
            "Epoch 39, Batch 900: Current Loss = 0.0340\n",
            "Epoch 39, Test Accuracy: 92.18%\n",
            "Epoch 40, Batch 0: Current Loss = 0.0194\n",
            "Epoch 40, Batch 100: Current Loss = 0.0153\n",
            "Epoch 40, Batch 200: Current Loss = 0.0427\n",
            "Epoch 40, Batch 300: Current Loss = 0.0070\n",
            "Epoch 40, Batch 400: Current Loss = 0.0143\n",
            "Epoch 40, Batch 500: Current Loss = 0.0007\n",
            "Epoch 40, Batch 600: Current Loss = 0.0393\n",
            "Epoch 40, Batch 700: Current Loss = 0.0620\n",
            "Epoch 40, Batch 800: Current Loss = 0.0361\n",
            "Epoch 40, Batch 900: Current Loss = 0.0066\n",
            "Epoch 40, Test Accuracy: 92.02%\n",
            "Epoch 41, Batch 0: Current Loss = 0.0051\n",
            "Epoch 41, Batch 100: Current Loss = 0.0122\n",
            "Epoch 41, Batch 200: Current Loss = 0.0297\n",
            "Epoch 41, Batch 300: Current Loss = 0.0041\n",
            "Epoch 41, Batch 400: Current Loss = 0.0009\n",
            "Epoch 41, Batch 500: Current Loss = 0.0003\n",
            "Epoch 41, Batch 600: Current Loss = 0.0005\n",
            "Epoch 41, Batch 700: Current Loss = 0.0006\n",
            "Epoch 41, Batch 800: Current Loss = 0.0051\n",
            "Epoch 41, Batch 900: Current Loss = 0.0084\n",
            "Epoch 41, Test Accuracy: 92.24%\n",
            "Epoch 42, Batch 0: Current Loss = 0.0002\n",
            "Epoch 42, Batch 100: Current Loss = 0.0012\n",
            "Epoch 42, Batch 200: Current Loss = 0.0012\n",
            "Epoch 42, Batch 300: Current Loss = 0.1487\n",
            "Epoch 42, Batch 400: Current Loss = 0.0012\n",
            "Epoch 42, Batch 500: Current Loss = 0.0003\n",
            "Epoch 42, Batch 600: Current Loss = 0.0003\n",
            "Epoch 42, Batch 700: Current Loss = 0.0138\n",
            "Epoch 42, Batch 800: Current Loss = 0.0177\n",
            "Epoch 42, Batch 900: Current Loss = 0.0011\n",
            "Epoch 42, Test Accuracy: 92.17%\n",
            "Epoch 43, Batch 0: Current Loss = 0.0309\n",
            "Epoch 43, Batch 100: Current Loss = 0.0005\n",
            "Epoch 43, Batch 200: Current Loss = 0.0107\n",
            "Epoch 43, Batch 300: Current Loss = 0.0009\n",
            "Epoch 43, Batch 400: Current Loss = 0.0059\n",
            "Epoch 43, Batch 500: Current Loss = 0.0203\n",
            "Epoch 43, Batch 600: Current Loss = 0.0580\n",
            "Epoch 43, Batch 700: Current Loss = 0.0030\n",
            "Epoch 43, Batch 800: Current Loss = 0.0114\n",
            "Epoch 43, Batch 900: Current Loss = 0.0045\n",
            "Epoch 43, Test Accuracy: 92.49%\n",
            "Epoch 44, Batch 0: Current Loss = 0.0011\n",
            "Epoch 44, Batch 100: Current Loss = 0.0001\n",
            "Epoch 44, Batch 200: Current Loss = 0.0245\n",
            "Epoch 44, Batch 300: Current Loss = 0.0020\n",
            "Epoch 44, Batch 400: Current Loss = 0.0032\n",
            "Epoch 44, Batch 500: Current Loss = 0.0008\n",
            "Epoch 44, Batch 600: Current Loss = 0.0029\n",
            "Epoch 44, Batch 700: Current Loss = 0.0001\n",
            "Epoch 44, Batch 800: Current Loss = 0.0543\n",
            "Epoch 44, Batch 900: Current Loss = 0.0016\n",
            "Epoch 44, Test Accuracy: 92.58%\n",
            "Epoch 45, Batch 0: Current Loss = 0.0016\n",
            "Epoch 45, Batch 100: Current Loss = 0.0002\n",
            "Epoch 45, Batch 200: Current Loss = 0.0113\n",
            "Epoch 45, Batch 300: Current Loss = 0.0011\n",
            "Epoch 45, Batch 400: Current Loss = 0.0332\n",
            "Epoch 45, Batch 500: Current Loss = 0.0004\n",
            "Epoch 45, Batch 600: Current Loss = 0.0472\n",
            "Epoch 45, Batch 700: Current Loss = 0.0013\n",
            "Epoch 45, Batch 800: Current Loss = 0.0029\n",
            "Epoch 45, Batch 900: Current Loss = 0.0003\n",
            "Epoch 45, Test Accuracy: 92.67%\n",
            "Epoch 46, Batch 0: Current Loss = 0.0101\n",
            "Epoch 46, Batch 100: Current Loss = 0.0018\n",
            "Epoch 46, Batch 200: Current Loss = 0.0006\n",
            "Epoch 46, Batch 300: Current Loss = 0.0042\n",
            "Epoch 46, Batch 400: Current Loss = 0.0049\n",
            "Epoch 46, Batch 500: Current Loss = 0.0108\n",
            "Epoch 46, Batch 600: Current Loss = 0.0128\n",
            "Epoch 46, Batch 700: Current Loss = 0.0228\n",
            "Epoch 46, Batch 800: Current Loss = 0.0023\n",
            "Epoch 46, Batch 900: Current Loss = 0.0075\n",
            "Epoch 46, Test Accuracy: 92.23%\n",
            "Epoch 47, Batch 0: Current Loss = 0.0240\n",
            "Epoch 47, Batch 100: Current Loss = 0.0001\n",
            "Epoch 47, Batch 200: Current Loss = 0.0109\n",
            "Epoch 47, Batch 300: Current Loss = 0.0024\n",
            "Epoch 47, Batch 400: Current Loss = 0.0005\n",
            "Epoch 47, Batch 500: Current Loss = 0.0418\n",
            "Epoch 47, Batch 600: Current Loss = 0.0001\n",
            "Epoch 47, Batch 700: Current Loss = 0.0004\n",
            "Epoch 47, Batch 800: Current Loss = 0.0030\n",
            "Epoch 47, Batch 900: Current Loss = 0.0140\n",
            "Epoch 47, Test Accuracy: 92.33%\n",
            "Epoch 48, Batch 0: Current Loss = 0.0011\n",
            "Epoch 48, Batch 100: Current Loss = 0.0012\n",
            "Epoch 48, Batch 200: Current Loss = 0.1561\n",
            "Epoch 48, Batch 300: Current Loss = 0.0008\n",
            "Epoch 48, Batch 400: Current Loss = 0.0004\n",
            "Epoch 48, Batch 500: Current Loss = 0.0015\n",
            "Epoch 48, Batch 600: Current Loss = 0.0660\n",
            "Epoch 48, Batch 700: Current Loss = 0.0095\n",
            "Epoch 48, Batch 800: Current Loss = 0.0686\n",
            "Epoch 48, Batch 900: Current Loss = 0.0006\n",
            "Epoch 48, Test Accuracy: 92.71%\n",
            "Epoch 49, Batch 0: Current Loss = 0.0007\n",
            "Epoch 49, Batch 100: Current Loss = 0.0120\n",
            "Epoch 49, Batch 200: Current Loss = 0.0113\n",
            "Epoch 49, Batch 300: Current Loss = 0.0395\n",
            "Epoch 49, Batch 400: Current Loss = 0.0037\n",
            "Epoch 49, Batch 500: Current Loss = 0.0108\n",
            "Epoch 49, Batch 600: Current Loss = 0.0074\n",
            "Epoch 49, Batch 700: Current Loss = 0.0125\n",
            "Epoch 49, Batch 800: Current Loss = 0.0018\n",
            "Epoch 49, Batch 900: Current Loss = 0.0066\n",
            "Epoch 49, Test Accuracy: 91.77%\n",
            "Epoch 50, Batch 0: Current Loss = 0.0005\n",
            "Epoch 50, Batch 100: Current Loss = 0.0007\n",
            "Epoch 50, Batch 200: Current Loss = 0.0355\n",
            "Epoch 50, Batch 300: Current Loss = 0.0001\n",
            "Epoch 50, Batch 400: Current Loss = 0.0014\n",
            "Epoch 50, Batch 500: Current Loss = 0.1311\n",
            "Epoch 50, Batch 600: Current Loss = 0.0571\n",
            "Epoch 50, Batch 700: Current Loss = 0.0131\n",
            "Epoch 50, Batch 800: Current Loss = 0.0066\n",
            "Epoch 50, Batch 900: Current Loss = 0.0095\n",
            "Epoch 50, Test Accuracy: 92.45%\n",
            "Epoch 51, Batch 0: Current Loss = 0.0001\n",
            "Epoch 51, Batch 100: Current Loss = 0.0003\n",
            "Epoch 51, Batch 200: Current Loss = 0.0508\n",
            "Epoch 51, Batch 300: Current Loss = 0.0010\n",
            "Epoch 51, Batch 400: Current Loss = 0.0012\n",
            "Epoch 51, Batch 500: Current Loss = 0.0100\n",
            "Epoch 51, Batch 600: Current Loss = 0.0036\n",
            "Epoch 51, Batch 700: Current Loss = 0.0008\n",
            "Epoch 51, Batch 800: Current Loss = 0.0020\n",
            "Epoch 51, Batch 900: Current Loss = 0.0225\n",
            "Epoch 51, Test Accuracy: 92.28%\n",
            "Epoch 52, Batch 0: Current Loss = 0.0005\n",
            "Epoch 52, Batch 100: Current Loss = 0.0051\n",
            "Epoch 52, Batch 200: Current Loss = 0.0020\n",
            "Epoch 52, Batch 300: Current Loss = 0.0306\n",
            "Epoch 52, Batch 400: Current Loss = 0.0977\n",
            "Epoch 52, Batch 500: Current Loss = 0.0005\n",
            "Epoch 52, Batch 600: Current Loss = 0.0109\n",
            "Epoch 52, Batch 700: Current Loss = 0.0002\n",
            "Epoch 52, Batch 800: Current Loss = 0.0754\n",
            "Epoch 52, Batch 900: Current Loss = 0.0001\n",
            "Epoch 52, Test Accuracy: 92.52%\n",
            "Epoch 53, Batch 0: Current Loss = 0.0019\n",
            "Epoch 53, Batch 100: Current Loss = 0.0020\n",
            "Epoch 53, Batch 200: Current Loss = 0.0025\n",
            "Epoch 53, Batch 300: Current Loss = 0.0112\n",
            "Epoch 53, Batch 400: Current Loss = 0.0004\n",
            "Epoch 53, Batch 500: Current Loss = 0.0222\n",
            "Epoch 53, Batch 600: Current Loss = 0.0001\n",
            "Epoch 53, Batch 700: Current Loss = 0.0001\n",
            "Epoch 53, Batch 800: Current Loss = 0.0006\n",
            "Epoch 53, Batch 900: Current Loss = 0.0004\n",
            "Epoch 53, Test Accuracy: 92.30%\n",
            "Epoch 54, Batch 0: Current Loss = 0.0146\n",
            "Epoch 54, Batch 100: Current Loss = 0.0003\n",
            "Epoch 54, Batch 200: Current Loss = 0.0004\n",
            "Epoch 54, Batch 300: Current Loss = 0.0032\n",
            "Epoch 54, Batch 400: Current Loss = 0.1560\n",
            "Epoch 54, Batch 500: Current Loss = 0.0002\n",
            "Epoch 54, Batch 600: Current Loss = 0.0036\n",
            "Epoch 54, Batch 700: Current Loss = 0.0087\n",
            "Epoch 54, Batch 800: Current Loss = 0.0010\n",
            "Epoch 54, Batch 900: Current Loss = 0.0035\n",
            "Epoch 54, Test Accuracy: 92.18%\n",
            "Epoch 55, Batch 0: Current Loss = 0.0031\n",
            "Epoch 55, Batch 100: Current Loss = 0.0005\n",
            "Epoch 55, Batch 200: Current Loss = 0.0367\n",
            "Epoch 55, Batch 300: Current Loss = 0.0030\n",
            "Epoch 55, Batch 400: Current Loss = 0.0131\n",
            "Epoch 55, Batch 500: Current Loss = 0.0005\n",
            "Epoch 55, Batch 600: Current Loss = 0.0182\n",
            "Epoch 55, Batch 700: Current Loss = 0.0011\n",
            "Epoch 55, Batch 800: Current Loss = 0.0169\n",
            "Epoch 55, Batch 900: Current Loss = 0.0003\n",
            "Epoch 55, Test Accuracy: 92.34%\n",
            "Epoch 56, Batch 0: Current Loss = 0.0468\n",
            "Epoch 56, Batch 100: Current Loss = 0.0196\n",
            "Epoch 56, Batch 200: Current Loss = 0.0054\n",
            "Epoch 56, Batch 300: Current Loss = 0.0004\n",
            "Epoch 56, Batch 400: Current Loss = 0.0906\n",
            "Epoch 56, Batch 500: Current Loss = 0.0156\n",
            "Epoch 56, Batch 600: Current Loss = 0.0073\n",
            "Epoch 56, Batch 700: Current Loss = 0.0037\n",
            "Epoch 56, Batch 800: Current Loss = 0.0062\n",
            "Epoch 56, Batch 900: Current Loss = 0.0001\n",
            "Epoch 56, Test Accuracy: 92.69%\n",
            "Epoch 57, Batch 0: Current Loss = 0.0051\n",
            "Epoch 57, Batch 100: Current Loss = 0.0017\n",
            "Epoch 57, Batch 200: Current Loss = 0.0046\n",
            "Epoch 57, Batch 300: Current Loss = 0.0187\n",
            "Epoch 57, Batch 400: Current Loss = 0.0020\n",
            "Epoch 57, Batch 500: Current Loss = 0.0066\n",
            "Epoch 57, Batch 600: Current Loss = 0.0033\n",
            "Epoch 57, Batch 700: Current Loss = 0.0020\n",
            "Epoch 57, Batch 800: Current Loss = 0.0002\n",
            "Epoch 57, Batch 900: Current Loss = 0.0002\n",
            "Epoch 57, Test Accuracy: 92.41%\n",
            "Epoch 58, Batch 0: Current Loss = 0.0005\n",
            "Epoch 58, Batch 100: Current Loss = 0.0011\n",
            "Epoch 58, Batch 200: Current Loss = 0.0160\n",
            "Epoch 58, Batch 300: Current Loss = 0.0247\n",
            "Epoch 58, Batch 400: Current Loss = 0.0039\n",
            "Epoch 58, Batch 500: Current Loss = 0.0040\n",
            "Epoch 58, Batch 600: Current Loss = 0.0002\n",
            "Epoch 58, Batch 700: Current Loss = 0.0005\n",
            "Epoch 58, Batch 800: Current Loss = 0.0003\n",
            "Epoch 58, Batch 900: Current Loss = 0.0000\n",
            "Epoch 58, Test Accuracy: 92.65%\n",
            "Epoch 59, Batch 0: Current Loss = 0.0264\n",
            "Epoch 59, Batch 100: Current Loss = 0.0201\n",
            "Epoch 59, Batch 200: Current Loss = 0.0672\n",
            "Epoch 59, Batch 300: Current Loss = 0.0156\n",
            "Epoch 59, Batch 400: Current Loss = 0.0024\n",
            "Epoch 59, Batch 500: Current Loss = 0.0014\n",
            "Epoch 59, Batch 600: Current Loss = 0.0022\n",
            "Epoch 59, Batch 700: Current Loss = 0.0003\n",
            "Epoch 59, Batch 800: Current Loss = 0.0166\n",
            "Epoch 59, Batch 900: Current Loss = 0.0015\n",
            "Epoch 59, Test Accuracy: 92.41%\n",
            "Epoch 60, Batch 0: Current Loss = 0.0002\n",
            "Epoch 60, Batch 100: Current Loss = 0.0057\n",
            "Epoch 60, Batch 200: Current Loss = 0.1020\n",
            "Epoch 60, Batch 300: Current Loss = 0.0012\n",
            "Epoch 60, Batch 400: Current Loss = 0.0004\n",
            "Epoch 60, Batch 500: Current Loss = 0.0003\n",
            "Epoch 60, Batch 600: Current Loss = 0.0174\n",
            "Epoch 60, Batch 700: Current Loss = 0.0005\n",
            "Epoch 60, Batch 800: Current Loss = 0.0004\n",
            "Epoch 60, Batch 900: Current Loss = 0.0003\n",
            "Epoch 60, Test Accuracy: 92.85%\n",
            "New best accuracy: 92.85%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 61, Batch 0: Current Loss = 0.0005\n",
            "Epoch 61, Batch 100: Current Loss = 0.0633\n",
            "Epoch 61, Batch 200: Current Loss = 0.0014\n",
            "Epoch 61, Batch 300: Current Loss = 0.0287\n",
            "Epoch 61, Batch 400: Current Loss = 0.0008\n",
            "Epoch 61, Batch 500: Current Loss = 0.0000\n",
            "Epoch 61, Batch 600: Current Loss = 0.0609\n",
            "Epoch 61, Batch 700: Current Loss = 0.0000\n",
            "Epoch 61, Batch 800: Current Loss = 0.0372\n",
            "Epoch 61, Batch 900: Current Loss = 0.0005\n",
            "Epoch 61, Test Accuracy: 92.23%\n",
            "Epoch 62, Batch 0: Current Loss = 0.1335\n",
            "Epoch 62, Batch 100: Current Loss = 0.0091\n",
            "Epoch 62, Batch 200: Current Loss = 0.0003\n",
            "Epoch 62, Batch 300: Current Loss = 0.0124\n",
            "Epoch 62, Batch 400: Current Loss = 0.0266\n",
            "Epoch 62, Batch 500: Current Loss = 0.0004\n",
            "Epoch 62, Batch 600: Current Loss = 0.1605\n",
            "Epoch 62, Batch 700: Current Loss = 0.0022\n",
            "Epoch 62, Batch 800: Current Loss = 0.0701\n",
            "Epoch 62, Batch 900: Current Loss = 0.0007\n",
            "Epoch 62, Test Accuracy: 92.66%\n",
            "Epoch 63, Batch 0: Current Loss = 0.0016\n",
            "Epoch 63, Batch 100: Current Loss = 0.0133\n",
            "Epoch 63, Batch 200: Current Loss = 0.1320\n",
            "Epoch 63, Batch 300: Current Loss = 0.0006\n",
            "Epoch 63, Batch 400: Current Loss = 0.0132\n",
            "Epoch 63, Batch 500: Current Loss = 0.0105\n",
            "Epoch 63, Batch 600: Current Loss = 0.0004\n",
            "Epoch 63, Batch 700: Current Loss = 0.0045\n",
            "Epoch 63, Batch 800: Current Loss = 0.0109\n",
            "Epoch 63, Batch 900: Current Loss = 0.0277\n",
            "Epoch 63, Test Accuracy: 92.84%\n",
            "Epoch 64, Batch 0: Current Loss = 0.0009\n",
            "Epoch 64, Batch 100: Current Loss = 0.0001\n",
            "Epoch 64, Batch 200: Current Loss = 0.0000\n",
            "Epoch 64, Batch 300: Current Loss = 0.0009\n",
            "Epoch 64, Batch 400: Current Loss = 0.0099\n",
            "Epoch 64, Batch 500: Current Loss = 0.0006\n",
            "Epoch 64, Batch 600: Current Loss = 0.0017\n",
            "Epoch 64, Batch 700: Current Loss = 0.0005\n",
            "Epoch 64, Batch 800: Current Loss = 0.0081\n",
            "Epoch 64, Batch 900: Current Loss = 0.0038\n",
            "Epoch 64, Test Accuracy: 92.47%\n",
            "Epoch 65, Batch 0: Current Loss = 0.0683\n",
            "Epoch 65, Batch 100: Current Loss = 0.0030\n",
            "Epoch 65, Batch 200: Current Loss = 0.0007\n",
            "Epoch 65, Batch 300: Current Loss = 0.0002\n",
            "Epoch 65, Batch 400: Current Loss = 0.0626\n",
            "Epoch 65, Batch 500: Current Loss = 0.0004\n",
            "Epoch 65, Batch 600: Current Loss = 0.0026\n",
            "Epoch 65, Batch 700: Current Loss = 0.0532\n",
            "Epoch 65, Batch 800: Current Loss = 0.0308\n",
            "Epoch 65, Batch 900: Current Loss = 0.0013\n",
            "Epoch 65, Test Accuracy: 92.46%\n",
            "Epoch 66, Batch 0: Current Loss = 0.0003\n",
            "Epoch 66, Batch 100: Current Loss = 0.0002\n",
            "Epoch 66, Batch 200: Current Loss = 0.0080\n",
            "Epoch 66, Batch 300: Current Loss = 0.0724\n",
            "Epoch 66, Batch 400: Current Loss = 0.0200\n",
            "Epoch 66, Batch 500: Current Loss = 0.0003\n",
            "Epoch 66, Batch 600: Current Loss = 0.0000\n",
            "Epoch 66, Batch 700: Current Loss = 0.0005\n",
            "Epoch 66, Batch 800: Current Loss = 0.0719\n",
            "Epoch 66, Batch 900: Current Loss = 0.0002\n",
            "Epoch 66, Test Accuracy: 92.65%\n",
            "Epoch 67, Batch 0: Current Loss = 0.0520\n",
            "Epoch 67, Batch 100: Current Loss = 0.0054\n",
            "Epoch 67, Batch 200: Current Loss = 0.0309\n",
            "Epoch 67, Batch 300: Current Loss = 0.0002\n",
            "Epoch 67, Batch 400: Current Loss = 0.0111\n",
            "Epoch 67, Batch 500: Current Loss = 0.0001\n",
            "Epoch 67, Batch 600: Current Loss = 0.0704\n",
            "Epoch 67, Batch 700: Current Loss = 0.0019\n",
            "Epoch 67, Batch 800: Current Loss = 0.0324\n",
            "Epoch 67, Batch 900: Current Loss = 0.0023\n",
            "Epoch 67, Test Accuracy: 92.73%\n",
            "Epoch 68, Batch 0: Current Loss = 0.0056\n",
            "Epoch 68, Batch 100: Current Loss = 0.0000\n",
            "Epoch 68, Batch 200: Current Loss = 0.0214\n",
            "Epoch 68, Batch 300: Current Loss = 0.0070\n",
            "Epoch 68, Batch 400: Current Loss = 0.0899\n",
            "Epoch 68, Batch 500: Current Loss = 0.0013\n",
            "Epoch 68, Batch 600: Current Loss = 0.0001\n",
            "Epoch 68, Batch 700: Current Loss = 0.0010\n",
            "Epoch 68, Batch 800: Current Loss = 0.0015\n",
            "Epoch 68, Batch 900: Current Loss = 0.0001\n",
            "Epoch 68, Test Accuracy: 92.68%\n",
            "Epoch 69, Batch 0: Current Loss = 0.0223\n",
            "Epoch 69, Batch 100: Current Loss = 0.0001\n",
            "Epoch 69, Batch 200: Current Loss = 0.0004\n",
            "Epoch 69, Batch 300: Current Loss = 0.0396\n",
            "Epoch 69, Batch 400: Current Loss = 0.0024\n",
            "Epoch 69, Batch 500: Current Loss = 0.0002\n",
            "Epoch 69, Batch 600: Current Loss = 0.0002\n",
            "Epoch 69, Batch 700: Current Loss = 0.0140\n",
            "Epoch 69, Batch 800: Current Loss = 0.0088\n",
            "Epoch 69, Batch 900: Current Loss = 0.0067\n",
            "Epoch 69, Test Accuracy: 92.26%\n",
            "Epoch 70, Batch 0: Current Loss = 0.0495\n",
            "Epoch 70, Batch 100: Current Loss = 0.0027\n",
            "Epoch 70, Batch 200: Current Loss = 0.0005\n",
            "Epoch 70, Batch 300: Current Loss = 0.0001\n",
            "Epoch 70, Batch 400: Current Loss = 0.0034\n",
            "Epoch 70, Batch 500: Current Loss = 0.0075\n",
            "Epoch 70, Batch 600: Current Loss = 0.0008\n",
            "Epoch 70, Batch 700: Current Loss = 0.1356\n",
            "Epoch 70, Batch 800: Current Loss = 0.0087\n",
            "Epoch 70, Batch 900: Current Loss = 0.0026\n",
            "Epoch 70, Test Accuracy: 92.69%\n",
            "Epoch 71, Batch 0: Current Loss = 0.0000\n",
            "Epoch 71, Batch 100: Current Loss = 0.0001\n",
            "Epoch 71, Batch 200: Current Loss = 0.0004\n",
            "Epoch 71, Batch 300: Current Loss = 0.0057\n",
            "Epoch 71, Batch 400: Current Loss = 0.0031\n",
            "Epoch 71, Batch 500: Current Loss = 0.0058\n",
            "Epoch 71, Batch 600: Current Loss = 0.0001\n",
            "Epoch 71, Batch 700: Current Loss = 0.0001\n",
            "Epoch 71, Batch 800: Current Loss = 0.0005\n",
            "Epoch 71, Batch 900: Current Loss = 0.0000\n",
            "Epoch 71, Test Accuracy: 92.76%\n",
            "Epoch 72, Batch 0: Current Loss = 0.0009\n",
            "Epoch 72, Batch 100: Current Loss = 0.0003\n",
            "Epoch 72, Batch 200: Current Loss = 0.0008\n",
            "Epoch 72, Batch 300: Current Loss = 0.0030\n",
            "Epoch 72, Batch 400: Current Loss = 0.0075\n",
            "Epoch 72, Batch 500: Current Loss = 0.0049\n",
            "Epoch 72, Batch 600: Current Loss = 0.0002\n",
            "Epoch 72, Batch 700: Current Loss = 0.0006\n",
            "Epoch 72, Batch 800: Current Loss = 0.0001\n",
            "Epoch 72, Batch 900: Current Loss = 0.0019\n",
            "Epoch 72, Test Accuracy: 92.82%\n",
            "Epoch 73, Batch 0: Current Loss = 0.0000\n",
            "Epoch 73, Batch 100: Current Loss = 0.0000\n",
            "Epoch 73, Batch 200: Current Loss = 0.0065\n",
            "Epoch 73, Batch 300: Current Loss = 0.0026\n",
            "Epoch 73, Batch 400: Current Loss = 0.0248\n",
            "Epoch 73, Batch 500: Current Loss = 0.0017\n",
            "Epoch 73, Batch 600: Current Loss = 0.0352\n",
            "Epoch 73, Batch 700: Current Loss = 0.0001\n",
            "Epoch 73, Batch 800: Current Loss = 0.0024\n",
            "Epoch 73, Batch 900: Current Loss = 0.0018\n",
            "Epoch 73, Test Accuracy: 92.59%\n",
            "Epoch 74, Batch 0: Current Loss = 0.0006\n",
            "Epoch 74, Batch 100: Current Loss = 0.0009\n",
            "Epoch 74, Batch 200: Current Loss = 0.0017\n",
            "Epoch 74, Batch 300: Current Loss = 0.0007\n",
            "Epoch 74, Batch 400: Current Loss = 0.0012\n",
            "Epoch 74, Batch 500: Current Loss = 0.0000\n",
            "Epoch 74, Batch 600: Current Loss = 0.0821\n",
            "Epoch 74, Batch 700: Current Loss = 0.0239\n",
            "Epoch 74, Batch 800: Current Loss = 0.0000\n",
            "Epoch 74, Batch 900: Current Loss = 0.0001\n",
            "Epoch 74, Test Accuracy: 92.76%\n",
            "Epoch 75, Batch 0: Current Loss = 0.0015\n",
            "Epoch 75, Batch 100: Current Loss = 0.0016\n",
            "Epoch 75, Batch 200: Current Loss = 0.0117\n",
            "Epoch 75, Batch 300: Current Loss = 0.0000\n",
            "Epoch 75, Batch 400: Current Loss = 0.0006\n",
            "Epoch 75, Batch 500: Current Loss = 0.0000\n",
            "Epoch 75, Batch 600: Current Loss = 0.0002\n",
            "Epoch 75, Batch 700: Current Loss = 0.0078\n",
            "Epoch 75, Batch 800: Current Loss = 0.0174\n",
            "Epoch 75, Batch 900: Current Loss = 0.0062\n",
            "Epoch 75, Test Accuracy: 92.13%\n",
            "Epoch 76, Batch 0: Current Loss = 0.0010\n",
            "Epoch 76, Batch 100: Current Loss = 0.0181\n",
            "Epoch 76, Batch 200: Current Loss = 0.0002\n",
            "Epoch 76, Batch 300: Current Loss = 0.0726\n",
            "Epoch 76, Batch 400: Current Loss = 0.0041\n",
            "Epoch 76, Batch 500: Current Loss = 0.0000\n",
            "Epoch 76, Batch 600: Current Loss = 0.0127\n",
            "Epoch 76, Batch 700: Current Loss = 0.0003\n",
            "Epoch 76, Batch 800: Current Loss = 0.0142\n",
            "Epoch 76, Batch 900: Current Loss = 0.0033\n",
            "Epoch 76, Test Accuracy: 92.36%\n",
            "Epoch 77, Batch 0: Current Loss = 0.0043\n",
            "Epoch 77, Batch 100: Current Loss = 0.0003\n",
            "Epoch 77, Batch 200: Current Loss = 0.0407\n",
            "Epoch 77, Batch 300: Current Loss = 0.0221\n",
            "Epoch 77, Batch 400: Current Loss = 0.0059\n",
            "Epoch 77, Batch 500: Current Loss = 0.0046\n",
            "Epoch 77, Batch 600: Current Loss = 0.0166\n",
            "Epoch 77, Batch 700: Current Loss = 0.0001\n",
            "Epoch 77, Batch 800: Current Loss = 0.0026\n",
            "Epoch 77, Batch 900: Current Loss = 0.0001\n",
            "Epoch 77, Test Accuracy: 92.54%\n",
            "Epoch 78, Batch 0: Current Loss = 0.0330\n",
            "Epoch 78, Batch 100: Current Loss = 0.0002\n",
            "Epoch 78, Batch 200: Current Loss = 0.0032\n",
            "Epoch 78, Batch 300: Current Loss = 0.0012\n",
            "Epoch 78, Batch 400: Current Loss = 0.0003\n",
            "Epoch 78, Batch 500: Current Loss = 0.0061\n",
            "Epoch 78, Batch 600: Current Loss = 0.0001\n",
            "Epoch 78, Batch 700: Current Loss = 0.0001\n",
            "Epoch 78, Batch 800: Current Loss = 0.0057\n",
            "Epoch 78, Batch 900: Current Loss = 0.0068\n",
            "Epoch 78, Test Accuracy: 92.29%\n",
            "Epoch 79, Batch 0: Current Loss = 0.0180\n",
            "Epoch 79, Batch 100: Current Loss = 0.0016\n",
            "Epoch 79, Batch 200: Current Loss = 0.0014\n",
            "Epoch 79, Batch 300: Current Loss = 0.0044\n",
            "Epoch 79, Batch 400: Current Loss = 0.0006\n",
            "Epoch 79, Batch 500: Current Loss = 0.0111\n",
            "Epoch 79, Batch 600: Current Loss = 0.0075\n",
            "Epoch 79, Batch 700: Current Loss = 0.0000\n",
            "Epoch 79, Batch 800: Current Loss = 0.0428\n",
            "Epoch 79, Batch 900: Current Loss = 0.0027\n",
            "Epoch 79, Test Accuracy: 92.57%\n",
            "Epoch 80, Batch 0: Current Loss = 0.0023\n",
            "Epoch 80, Batch 100: Current Loss = 0.0008\n",
            "Epoch 80, Batch 200: Current Loss = 0.0098\n",
            "Epoch 80, Batch 300: Current Loss = 0.0166\n",
            "Epoch 80, Batch 400: Current Loss = 0.0003\n",
            "Epoch 80, Batch 500: Current Loss = 0.0000\n",
            "Epoch 80, Batch 600: Current Loss = 0.0008\n",
            "Epoch 80, Batch 700: Current Loss = 0.0000\n",
            "Epoch 80, Batch 800: Current Loss = 0.0010\n",
            "Epoch 80, Batch 900: Current Loss = 0.0152\n",
            "Epoch 80, Test Accuracy: 92.70%\n",
            "Epoch 81, Batch 0: Current Loss = 0.0076\n",
            "Epoch 81, Batch 100: Current Loss = 0.0000\n",
            "Epoch 81, Batch 200: Current Loss = 0.0025\n",
            "Epoch 81, Batch 300: Current Loss = 0.0479\n",
            "Epoch 81, Batch 400: Current Loss = 0.0042\n",
            "Epoch 81, Batch 500: Current Loss = 0.0667\n",
            "Epoch 81, Batch 600: Current Loss = 0.0025\n",
            "Epoch 81, Batch 700: Current Loss = 0.0004\n",
            "Epoch 81, Batch 800: Current Loss = 0.0015\n",
            "Epoch 81, Batch 900: Current Loss = 0.0001\n",
            "Epoch 81, Test Accuracy: 92.75%\n",
            "Epoch 82, Batch 0: Current Loss = 0.0023\n",
            "Epoch 82, Batch 100: Current Loss = 0.0057\n",
            "Epoch 82, Batch 200: Current Loss = 0.0010\n",
            "Epoch 82, Batch 300: Current Loss = 0.0037\n",
            "Epoch 82, Batch 400: Current Loss = 0.0186\n",
            "Epoch 82, Batch 500: Current Loss = 0.0075\n",
            "Epoch 82, Batch 600: Current Loss = 0.0723\n",
            "Epoch 82, Batch 700: Current Loss = 0.0002\n",
            "Epoch 82, Batch 800: Current Loss = 0.0001\n",
            "Epoch 82, Batch 900: Current Loss = 0.0009\n",
            "Epoch 82, Test Accuracy: 92.56%\n",
            "Epoch 83, Batch 0: Current Loss = 0.0551\n",
            "Epoch 83, Batch 100: Current Loss = 0.0734\n",
            "Epoch 83, Batch 200: Current Loss = 0.0738\n",
            "Epoch 83, Batch 300: Current Loss = 0.0002\n",
            "Epoch 83, Batch 400: Current Loss = 0.0081\n",
            "Epoch 83, Batch 500: Current Loss = 0.0577\n",
            "Epoch 83, Batch 600: Current Loss = 0.0003\n",
            "Epoch 83, Batch 700: Current Loss = 0.0000\n",
            "Epoch 83, Batch 800: Current Loss = 0.0953\n",
            "Epoch 83, Batch 900: Current Loss = 0.0173\n",
            "Epoch 83, Test Accuracy: 93.08%\n",
            "New best accuracy: 93.08%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 84, Batch 0: Current Loss = 0.0001\n",
            "Epoch 84, Batch 100: Current Loss = 0.0056\n",
            "Epoch 84, Batch 200: Current Loss = 0.0008\n",
            "Epoch 84, Batch 300: Current Loss = 0.0089\n",
            "Epoch 84, Batch 400: Current Loss = 0.0003\n",
            "Epoch 84, Batch 500: Current Loss = 0.0000\n",
            "Epoch 84, Batch 600: Current Loss = 0.0000\n",
            "Epoch 84, Batch 700: Current Loss = 0.0003\n",
            "Epoch 84, Batch 800: Current Loss = 0.0265\n",
            "Epoch 84, Batch 900: Current Loss = 0.0009\n",
            "Epoch 84, Test Accuracy: 92.15%\n",
            "\n",
            "Training complete!\n",
            "Highest accuracy achieved during training: 93.08%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "\n",
        "class ConvolutionalNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvolutionalNet, self).__init__()\n",
        "        self.conv_layer1 = nn.Conv2d(1, 32, 3, padding=1)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(32)\n",
        "        self.conv_layer2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(64)\n",
        "        self.conv_layer3 = nn.Conv2d(64, 64, 3, padding=1)\n",
        "        self.batch_norm3 = nn.BatchNorm2d(64)\n",
        "        self.pooling_layer = nn.MaxPool2d(2, 2)\n",
        "        self.fc_layer1 = nn.Linear(64 * 7 * 7, 512)\n",
        "        self.dropout_layer = nn.Dropout(0.5)\n",
        "        self.fc_layer2 = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pooling_layer(F.relu(self.batch_norm1(self.conv_layer1(x))))\n",
        "        x = self.pooling_layer(F.relu(self.batch_norm2(self.conv_layer2(x))))\n",
        "        x = F.relu(self.batch_norm3(self.conv_layer3(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc_layer1(x))\n",
        "        x = self.dropout_layer(x)\n",
        "        x = self.fc_layer2(x)\n",
        "        return x\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, path='./data', is_train=True, transform=None):\n",
        "        self.dataset = datasets.FashionMNIST(\n",
        "            root=path,\n",
        "            train=is_train,\n",
        "            download=True\n",
        "        )\n",
        "\n",
        "        self.images = self.dataset.data.numpy()\n",
        "        self.labels = self.dataset.targets.numpy()\n",
        "        self.images = self.images.astype(np.float32) / 255.0\n",
        "        self.transform = transform\n",
        "\n",
        "        self.class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "                            'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = torch.FloatTensor(image).unsqueeze(0)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "def save_best_model(model, filepath='best_model.pt'):\n",
        "    torch.save(model.state_dict(), filepath)\n",
        "    print(f\"Best model saved as {filepath}\")\n",
        "\n",
        "def load_best_model(filepath='best_model.pt'):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = ConvolutionalNet().to(device)\n",
        "\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(filepath, map_location=device))\n",
        "        print(f\"Model loaded from {filepath}\")\n",
        "        return model\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Model file {filepath} not found.\")\n",
        "        return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Training started on device: {device}\")\n",
        "\n",
        "    train_dataset = ImageDataset(is_train=True)\n",
        "    test_dataset = ImageDataset(is_train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    model = ConvolutionalNet().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "    total_epochs = 85\n",
        "    highest_accuracy = 0.0\n",
        "    best_model_path = 'best_model.pt'\n",
        "\n",
        "    print(\"Training process initiated...\")\n",
        "\n",
        "    for epoch in range(total_epochs):\n",
        "        model.train()\n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(inputs)\n",
        "            loss = loss_function(predictions, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f\"Epoch {epoch}, Batch {batch_idx}: Current Loss = {loss.item():.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        correct_predictions = 0\n",
        "        total_samples = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in test_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                predictions = model(inputs)\n",
        "                _, predicted_labels = torch.max(predictions.data, 1)\n",
        "                total_samples += targets.size(0)\n",
        "                correct_predictions += (predicted_labels == targets).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct_predictions / total_samples\n",
        "        print(f\"Epoch {epoch}, Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        if accuracy > highest_accuracy:\n",
        "            highest_accuracy = accuracy\n",
        "            print(f\"New best accuracy: {accuracy:.2f}%\")\n",
        "            save_best_model(model, best_model_path)\n",
        "\n",
        "    print(f\"\\nTraining complete!\")\n",
        "    print(f\"Highest accuracy achieved during training: {highest_accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "id": "YdQd3ITLlu2F",
        "outputId": "3f97b978-e1e3-4164-e609-01247d8611a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started on device: cuda\n",
            "Training process initiated...\n",
            "Epoch 0, Batch 0: Current Loss = 2.3228\n",
            "Epoch 0, Batch 100: Current Loss = 0.3543\n",
            "Epoch 0, Batch 200: Current Loss = 0.2278\n",
            "Epoch 0, Batch 300: Current Loss = 0.5057\n",
            "Epoch 0, Batch 400: Current Loss = 0.2673\n",
            "Epoch 0, Batch 500: Current Loss = 0.2710\n",
            "Epoch 0, Batch 600: Current Loss = 0.3091\n",
            "Epoch 0, Batch 700: Current Loss = 0.4639\n",
            "Epoch 0, Batch 800: Current Loss = 0.2305\n",
            "Epoch 0, Batch 900: Current Loss = 0.2527\n",
            "Epoch 0, Test Accuracy: 89.63%\n",
            "New best accuracy: 89.63%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 1, Batch 0: Current Loss = 0.2450\n",
            "Epoch 1, Batch 100: Current Loss = 0.2011\n",
            "Epoch 1, Batch 200: Current Loss = 0.2248\n",
            "Epoch 1, Batch 300: Current Loss = 0.3591\n",
            "Epoch 1, Batch 400: Current Loss = 0.2751\n",
            "Epoch 1, Batch 500: Current Loss = 0.2265\n",
            "Epoch 1, Batch 600: Current Loss = 0.2792\n",
            "Epoch 1, Batch 700: Current Loss = 0.2681\n",
            "Epoch 1, Batch 800: Current Loss = 0.1370\n",
            "Epoch 1, Batch 900: Current Loss = 0.1564\n",
            "Epoch 1, Test Accuracy: 88.62%\n",
            "Epoch 2, Batch 0: Current Loss = 0.3848\n",
            "Epoch 2, Batch 100: Current Loss = 0.2915\n",
            "Epoch 2, Batch 200: Current Loss = 0.2948\n",
            "Epoch 2, Batch 300: Current Loss = 0.1579\n",
            "Epoch 2, Batch 400: Current Loss = 0.1344\n",
            "Epoch 2, Batch 500: Current Loss = 0.1273\n",
            "Epoch 2, Batch 600: Current Loss = 0.1573\n",
            "Epoch 2, Batch 700: Current Loss = 0.4387\n",
            "Epoch 2, Batch 800: Current Loss = 0.1856\n",
            "Epoch 2, Batch 900: Current Loss = 0.1246\n",
            "Epoch 2, Test Accuracy: 91.54%\n",
            "New best accuracy: 91.54%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 3, Batch 0: Current Loss = 0.2682\n",
            "Epoch 3, Batch 100: Current Loss = 0.2592\n",
            "Epoch 3, Batch 200: Current Loss = 0.1100\n",
            "Epoch 3, Batch 300: Current Loss = 0.1140\n",
            "Epoch 3, Batch 400: Current Loss = 0.1399\n",
            "Epoch 3, Batch 500: Current Loss = 0.2748\n",
            "Epoch 3, Batch 600: Current Loss = 0.2599\n",
            "Epoch 3, Batch 700: Current Loss = 0.1416\n",
            "Epoch 3, Batch 800: Current Loss = 0.2820\n",
            "Epoch 3, Batch 900: Current Loss = 0.2091\n",
            "Epoch 3, Test Accuracy: 92.08%\n",
            "New best accuracy: 92.08%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 4, Batch 0: Current Loss = 0.1500\n",
            "Epoch 4, Batch 100: Current Loss = 0.0540\n",
            "Epoch 4, Batch 200: Current Loss = 0.2301\n",
            "Epoch 4, Batch 300: Current Loss = 0.1838\n",
            "Epoch 4, Batch 400: Current Loss = 0.0873\n",
            "Epoch 4, Batch 500: Current Loss = 0.2567\n",
            "Epoch 4, Batch 600: Current Loss = 0.1178\n",
            "Epoch 4, Batch 700: Current Loss = 0.1740\n",
            "Epoch 4, Batch 800: Current Loss = 0.2745\n",
            "Epoch 4, Batch 900: Current Loss = 0.1297\n",
            "Epoch 4, Test Accuracy: 91.78%\n",
            "Epoch 5, Batch 0: Current Loss = 0.1779\n",
            "Epoch 5, Batch 100: Current Loss = 0.1691\n",
            "Epoch 5, Batch 200: Current Loss = 0.1435\n",
            "Epoch 5, Batch 300: Current Loss = 0.1211\n",
            "Epoch 5, Batch 400: Current Loss = 0.2242\n",
            "Epoch 5, Batch 500: Current Loss = 0.1428\n",
            "Epoch 5, Batch 600: Current Loss = 0.2169\n",
            "Epoch 5, Batch 700: Current Loss = 0.1575\n",
            "Epoch 5, Batch 800: Current Loss = 0.1820\n",
            "Epoch 5, Batch 900: Current Loss = 0.1406\n",
            "Epoch 5, Test Accuracy: 91.48%\n",
            "Epoch 6, Batch 0: Current Loss = 0.0972\n",
            "Epoch 6, Batch 100: Current Loss = 0.0632\n",
            "Epoch 6, Batch 200: Current Loss = 0.0959\n",
            "Epoch 6, Batch 300: Current Loss = 0.1202\n",
            "Epoch 6, Batch 400: Current Loss = 0.0858\n",
            "Epoch 6, Batch 500: Current Loss = 0.2245\n",
            "Epoch 6, Batch 600: Current Loss = 0.0631\n",
            "Epoch 6, Batch 700: Current Loss = 0.0439\n",
            "Epoch 6, Batch 800: Current Loss = 0.2283\n",
            "Epoch 6, Batch 900: Current Loss = 0.1759\n",
            "Epoch 6, Test Accuracy: 92.00%\n",
            "Epoch 7, Batch 0: Current Loss = 0.0809\n",
            "Epoch 7, Batch 100: Current Loss = 0.0708\n",
            "Epoch 7, Batch 200: Current Loss = 0.1044\n",
            "Epoch 7, Batch 300: Current Loss = 0.1079\n",
            "Epoch 7, Batch 400: Current Loss = 0.1496\n",
            "Epoch 7, Batch 500: Current Loss = 0.0885\n",
            "Epoch 7, Batch 600: Current Loss = 0.1716\n",
            "Epoch 7, Batch 700: Current Loss = 0.0986\n",
            "Epoch 7, Batch 800: Current Loss = 0.0802\n",
            "Epoch 7, Batch 900: Current Loss = 0.2146\n",
            "Epoch 7, Test Accuracy: 91.91%\n",
            "Epoch 8, Batch 0: Current Loss = 0.1324\n",
            "Epoch 8, Batch 100: Current Loss = 0.1208\n",
            "Epoch 8, Batch 200: Current Loss = 0.0367\n",
            "Epoch 8, Batch 300: Current Loss = 0.0414\n",
            "Epoch 8, Batch 400: Current Loss = 0.0469\n",
            "Epoch 8, Batch 500: Current Loss = 0.0873\n",
            "Epoch 8, Batch 600: Current Loss = 0.2434\n",
            "Epoch 8, Batch 700: Current Loss = 0.2422\n",
            "Epoch 8, Batch 800: Current Loss = 0.1470\n",
            "Epoch 8, Batch 900: Current Loss = 0.0823\n",
            "Epoch 8, Test Accuracy: 92.33%\n",
            "New best accuracy: 92.33%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 9, Batch 0: Current Loss = 0.0871\n",
            "Epoch 9, Batch 100: Current Loss = 0.0526\n",
            "Epoch 9, Batch 200: Current Loss = 0.1762\n",
            "Epoch 9, Batch 300: Current Loss = 0.2346\n",
            "Epoch 9, Batch 400: Current Loss = 0.1934\n",
            "Epoch 9, Batch 500: Current Loss = 0.0914\n",
            "Epoch 9, Batch 600: Current Loss = 0.1957\n",
            "Epoch 9, Batch 700: Current Loss = 0.1047\n",
            "Epoch 9, Batch 800: Current Loss = 0.1517\n",
            "Epoch 9, Batch 900: Current Loss = 0.1833\n",
            "Epoch 9, Test Accuracy: 92.59%\n",
            "New best accuracy: 92.59%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 10, Batch 0: Current Loss = 0.0945\n",
            "Epoch 10, Batch 100: Current Loss = 0.1091\n",
            "Epoch 10, Batch 200: Current Loss = 0.0314\n",
            "Epoch 10, Batch 300: Current Loss = 0.1066\n",
            "Epoch 10, Batch 400: Current Loss = 0.1293\n",
            "Epoch 10, Batch 500: Current Loss = 0.1468\n",
            "Epoch 10, Batch 600: Current Loss = 0.1520\n",
            "Epoch 10, Batch 700: Current Loss = 0.0354\n",
            "Epoch 10, Batch 800: Current Loss = 0.0527\n",
            "Epoch 10, Batch 900: Current Loss = 0.0624\n",
            "Epoch 10, Test Accuracy: 92.43%\n",
            "Epoch 11, Batch 0: Current Loss = 0.0381\n",
            "Epoch 11, Batch 100: Current Loss = 0.0684\n",
            "Epoch 11, Batch 200: Current Loss = 0.1262\n",
            "Epoch 11, Batch 300: Current Loss = 0.0353\n",
            "Epoch 11, Batch 400: Current Loss = 0.0874\n",
            "Epoch 11, Batch 500: Current Loss = 0.0588\n",
            "Epoch 11, Batch 600: Current Loss = 0.0260\n",
            "Epoch 11, Batch 700: Current Loss = 0.1022\n",
            "Epoch 11, Batch 800: Current Loss = 0.0333\n",
            "Epoch 11, Batch 900: Current Loss = 0.0632\n",
            "Epoch 11, Test Accuracy: 92.51%\n",
            "Epoch 12, Batch 0: Current Loss = 0.0650\n",
            "Epoch 12, Batch 100: Current Loss = 0.0726\n",
            "Epoch 12, Batch 200: Current Loss = 0.0292\n",
            "Epoch 12, Batch 300: Current Loss = 0.0463\n",
            "Epoch 12, Batch 400: Current Loss = 0.0269\n",
            "Epoch 12, Batch 500: Current Loss = 0.0341\n",
            "Epoch 12, Batch 600: Current Loss = 0.0754\n",
            "Epoch 12, Batch 700: Current Loss = 0.0615\n",
            "Epoch 12, Batch 800: Current Loss = 0.0275\n",
            "Epoch 12, Batch 900: Current Loss = 0.0160\n",
            "Epoch 12, Test Accuracy: 92.49%\n",
            "Epoch 13, Batch 0: Current Loss = 0.0524\n",
            "Epoch 13, Batch 100: Current Loss = 0.0471\n",
            "Epoch 13, Batch 200: Current Loss = 0.0354\n",
            "Epoch 13, Batch 300: Current Loss = 0.0867\n",
            "Epoch 13, Batch 400: Current Loss = 0.0357\n",
            "Epoch 13, Batch 500: Current Loss = 0.1274\n",
            "Epoch 13, Batch 600: Current Loss = 0.0249\n",
            "Epoch 13, Batch 700: Current Loss = 0.0412\n",
            "Epoch 13, Batch 800: Current Loss = 0.0255\n",
            "Epoch 13, Batch 900: Current Loss = 0.0571\n",
            "Epoch 13, Test Accuracy: 92.46%\n",
            "Epoch 14, Batch 0: Current Loss = 0.0716\n",
            "Epoch 14, Batch 100: Current Loss = 0.0560\n",
            "Epoch 14, Batch 200: Current Loss = 0.0474\n",
            "Epoch 14, Batch 300: Current Loss = 0.0513\n",
            "Epoch 14, Batch 400: Current Loss = 0.0533\n",
            "Epoch 14, Batch 500: Current Loss = 0.0661\n",
            "Epoch 14, Batch 600: Current Loss = 0.0360\n",
            "Epoch 14, Batch 700: Current Loss = 0.0152\n",
            "Epoch 14, Batch 800: Current Loss = 0.0101\n",
            "Epoch 14, Batch 900: Current Loss = 0.0086\n",
            "Epoch 14, Test Accuracy: 92.47%\n",
            "Epoch 15, Batch 0: Current Loss = 0.0139\n",
            "Epoch 15, Batch 100: Current Loss = 0.0095\n",
            "Epoch 15, Batch 200: Current Loss = 0.0749\n",
            "Epoch 15, Batch 300: Current Loss = 0.0277\n",
            "Epoch 15, Batch 400: Current Loss = 0.0224\n",
            "Epoch 15, Batch 500: Current Loss = 0.0205\n",
            "Epoch 15, Batch 600: Current Loss = 0.0493\n",
            "Epoch 15, Batch 700: Current Loss = 0.0411\n",
            "Epoch 15, Batch 800: Current Loss = 0.0482\n",
            "Epoch 15, Batch 900: Current Loss = 0.0277\n",
            "Epoch 15, Test Accuracy: 92.35%\n",
            "Epoch 16, Batch 0: Current Loss = 0.0440\n",
            "Epoch 16, Batch 100: Current Loss = 0.0338\n",
            "Epoch 16, Batch 200: Current Loss = 0.0247\n",
            "Epoch 16, Batch 300: Current Loss = 0.0841\n",
            "Epoch 16, Batch 400: Current Loss = 0.0214\n",
            "Epoch 16, Batch 500: Current Loss = 0.0079\n",
            "Epoch 16, Batch 600: Current Loss = 0.1070\n",
            "Epoch 16, Batch 700: Current Loss = 0.0118\n",
            "Epoch 16, Batch 800: Current Loss = 0.0176\n",
            "Epoch 16, Batch 900: Current Loss = 0.1289\n",
            "Epoch 16, Test Accuracy: 92.15%\n",
            "Epoch 17, Batch 0: Current Loss = 0.0113\n",
            "Epoch 17, Batch 100: Current Loss = 0.0744\n",
            "Epoch 17, Batch 200: Current Loss = 0.0674\n",
            "Epoch 17, Batch 300: Current Loss = 0.0284\n",
            "Epoch 17, Batch 400: Current Loss = 0.1026\n",
            "Epoch 17, Batch 500: Current Loss = 0.0390\n",
            "Epoch 17, Batch 600: Current Loss = 0.0692\n",
            "Epoch 17, Batch 700: Current Loss = 0.0401\n",
            "Epoch 17, Batch 800: Current Loss = 0.1892\n",
            "Epoch 17, Batch 900: Current Loss = 0.2072\n",
            "Epoch 17, Test Accuracy: 92.35%\n",
            "Epoch 18, Batch 0: Current Loss = 0.0212\n",
            "Epoch 18, Batch 100: Current Loss = 0.0976\n",
            "Epoch 18, Batch 200: Current Loss = 0.0191\n",
            "Epoch 18, Batch 300: Current Loss = 0.0238\n",
            "Epoch 18, Batch 400: Current Loss = 0.0061\n",
            "Epoch 18, Batch 500: Current Loss = 0.0305\n",
            "Epoch 18, Batch 600: Current Loss = 0.0655\n",
            "Epoch 18, Batch 700: Current Loss = 0.0105\n",
            "Epoch 18, Batch 800: Current Loss = 0.0154\n",
            "Epoch 18, Batch 900: Current Loss = 0.0452\n",
            "Epoch 18, Test Accuracy: 92.61%\n",
            "New best accuracy: 92.61%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 19, Batch 0: Current Loss = 0.0035\n",
            "Epoch 19, Batch 100: Current Loss = 0.0581\n",
            "Epoch 19, Batch 200: Current Loss = 0.0516\n",
            "Epoch 19, Batch 300: Current Loss = 0.0757\n",
            "Epoch 19, Batch 400: Current Loss = 0.0206\n",
            "Epoch 19, Batch 500: Current Loss = 0.0102\n",
            "Epoch 19, Batch 600: Current Loss = 0.0366\n",
            "Epoch 19, Batch 700: Current Loss = 0.0448\n",
            "Epoch 19, Batch 800: Current Loss = 0.1189\n",
            "Epoch 19, Batch 900: Current Loss = 0.0165\n",
            "Epoch 19, Test Accuracy: 92.53%\n",
            "Epoch 20, Batch 0: Current Loss = 0.0027\n",
            "Epoch 20, Batch 100: Current Loss = 0.0370\n",
            "Epoch 20, Batch 200: Current Loss = 0.0282\n",
            "Epoch 20, Batch 300: Current Loss = 0.0144\n",
            "Epoch 20, Batch 400: Current Loss = 0.0468\n",
            "Epoch 20, Batch 500: Current Loss = 0.0061\n",
            "Epoch 20, Batch 600: Current Loss = 0.0936\n",
            "Epoch 20, Batch 700: Current Loss = 0.0293\n",
            "Epoch 20, Batch 800: Current Loss = 0.0390\n",
            "Epoch 20, Batch 900: Current Loss = 0.0024\n",
            "Epoch 20, Test Accuracy: 92.56%\n",
            "Epoch 21, Batch 0: Current Loss = 0.0037\n",
            "Epoch 21, Batch 100: Current Loss = 0.0131\n",
            "Epoch 21, Batch 200: Current Loss = 0.0042\n",
            "Epoch 21, Batch 300: Current Loss = 0.0132\n",
            "Epoch 21, Batch 400: Current Loss = 0.0043\n",
            "Epoch 21, Batch 500: Current Loss = 0.0259\n",
            "Epoch 21, Batch 600: Current Loss = 0.0374\n",
            "Epoch 21, Batch 700: Current Loss = 0.0143\n",
            "Epoch 21, Batch 800: Current Loss = 0.0994\n",
            "Epoch 21, Batch 900: Current Loss = 0.0034\n",
            "Epoch 21, Test Accuracy: 92.30%\n",
            "Epoch 22, Batch 0: Current Loss = 0.1223\n",
            "Epoch 22, Batch 100: Current Loss = 0.0397\n",
            "Epoch 22, Batch 200: Current Loss = 0.0018\n",
            "Epoch 22, Batch 300: Current Loss = 0.0119\n",
            "Epoch 22, Batch 400: Current Loss = 0.0197\n",
            "Epoch 22, Batch 500: Current Loss = 0.0796\n",
            "Epoch 22, Batch 600: Current Loss = 0.0139\n",
            "Epoch 22, Batch 700: Current Loss = 0.0901\n",
            "Epoch 22, Batch 800: Current Loss = 0.0055\n",
            "Epoch 22, Batch 900: Current Loss = 0.0135\n",
            "Epoch 22, Test Accuracy: 92.61%\n",
            "Epoch 23, Batch 0: Current Loss = 0.0800\n",
            "Epoch 23, Batch 100: Current Loss = 0.0310\n",
            "Epoch 23, Batch 200: Current Loss = 0.0763\n",
            "Epoch 23, Batch 300: Current Loss = 0.0183\n",
            "Epoch 23, Batch 400: Current Loss = 0.0008\n",
            "Epoch 23, Batch 500: Current Loss = 0.0154\n",
            "Epoch 23, Batch 600: Current Loss = 0.0048\n",
            "Epoch 23, Batch 700: Current Loss = 0.0059\n",
            "Epoch 23, Batch 800: Current Loss = 0.0252\n",
            "Epoch 23, Batch 900: Current Loss = 0.0997\n",
            "Epoch 23, Test Accuracy: 92.52%\n",
            "Epoch 24, Batch 0: Current Loss = 0.0023\n",
            "Epoch 24, Batch 100: Current Loss = 0.0129\n",
            "Epoch 24, Batch 200: Current Loss = 0.0069\n",
            "Epoch 24, Batch 300: Current Loss = 0.0827\n",
            "Epoch 24, Batch 400: Current Loss = 0.0169\n",
            "Epoch 24, Batch 500: Current Loss = 0.0030\n",
            "Epoch 24, Batch 600: Current Loss = 0.0368\n",
            "Epoch 24, Batch 700: Current Loss = 0.0079\n",
            "Epoch 24, Batch 800: Current Loss = 0.0007\n",
            "Epoch 24, Batch 900: Current Loss = 0.0145\n",
            "Epoch 24, Test Accuracy: 92.45%\n",
            "Epoch 25, Batch 0: Current Loss = 0.0129\n",
            "Epoch 25, Batch 100: Current Loss = 0.0066\n",
            "Epoch 25, Batch 200: Current Loss = 0.0031\n",
            "Epoch 25, Batch 300: Current Loss = 0.0565\n",
            "Epoch 25, Batch 400: Current Loss = 0.0278\n",
            "Epoch 25, Batch 500: Current Loss = 0.0084\n",
            "Epoch 25, Batch 600: Current Loss = 0.0388\n",
            "Epoch 25, Batch 700: Current Loss = 0.0067\n",
            "Epoch 25, Batch 800: Current Loss = 0.0078\n",
            "Epoch 25, Batch 900: Current Loss = 0.0034\n",
            "Epoch 25, Test Accuracy: 92.31%\n",
            "Epoch 26, Batch 0: Current Loss = 0.0170\n",
            "Epoch 26, Batch 100: Current Loss = 0.0685\n",
            "Epoch 26, Batch 200: Current Loss = 0.0061\n",
            "Epoch 26, Batch 300: Current Loss = 0.0152\n",
            "Epoch 26, Batch 400: Current Loss = 0.0201\n",
            "Epoch 26, Batch 500: Current Loss = 0.0028\n",
            "Epoch 26, Batch 600: Current Loss = 0.0643\n",
            "Epoch 26, Batch 700: Current Loss = 0.0889\n",
            "Epoch 26, Batch 800: Current Loss = 0.0435\n",
            "Epoch 26, Batch 900: Current Loss = 0.0208\n",
            "Epoch 26, Test Accuracy: 92.54%\n",
            "Epoch 27, Batch 0: Current Loss = 0.0237\n",
            "Epoch 27, Batch 100: Current Loss = 0.0003\n",
            "Epoch 27, Batch 200: Current Loss = 0.0148\n",
            "Epoch 27, Batch 300: Current Loss = 0.0675\n",
            "Epoch 27, Batch 400: Current Loss = 0.0042\n",
            "Epoch 27, Batch 500: Current Loss = 0.0313\n",
            "Epoch 27, Batch 600: Current Loss = 0.0313\n",
            "Epoch 27, Batch 700: Current Loss = 0.0209\n",
            "Epoch 27, Batch 800: Current Loss = 0.0119\n",
            "Epoch 27, Batch 900: Current Loss = 0.0439\n",
            "Epoch 27, Test Accuracy: 92.60%\n",
            "Epoch 28, Batch 0: Current Loss = 0.0030\n",
            "Epoch 28, Batch 100: Current Loss = 0.0034\n",
            "Epoch 28, Batch 200: Current Loss = 0.1148\n",
            "Epoch 28, Batch 300: Current Loss = 0.0066\n",
            "Epoch 28, Batch 400: Current Loss = 0.0804\n",
            "Epoch 28, Batch 500: Current Loss = 0.0018\n",
            "Epoch 28, Batch 600: Current Loss = 0.0021\n",
            "Epoch 28, Batch 700: Current Loss = 0.0037\n",
            "Epoch 28, Batch 800: Current Loss = 0.0105\n",
            "Epoch 28, Batch 900: Current Loss = 0.0220\n",
            "Epoch 28, Test Accuracy: 92.59%\n",
            "Epoch 29, Batch 0: Current Loss = 0.0020\n",
            "Epoch 29, Batch 100: Current Loss = 0.0094\n",
            "Epoch 29, Batch 200: Current Loss = 0.0083\n",
            "Epoch 29, Batch 300: Current Loss = 0.0409\n",
            "Epoch 29, Batch 400: Current Loss = 0.0201\n",
            "Epoch 29, Batch 500: Current Loss = 0.0131\n",
            "Epoch 29, Batch 600: Current Loss = 0.0443\n",
            "Epoch 29, Batch 700: Current Loss = 0.0197\n",
            "Epoch 29, Batch 800: Current Loss = 0.0024\n",
            "Epoch 29, Batch 900: Current Loss = 0.1355\n",
            "Epoch 29, Test Accuracy: 92.81%\n",
            "New best accuracy: 92.81%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 30, Batch 0: Current Loss = 0.0141\n",
            "Epoch 30, Batch 100: Current Loss = 0.0151\n",
            "Epoch 30, Batch 200: Current Loss = 0.0198\n",
            "Epoch 30, Batch 300: Current Loss = 0.0058\n",
            "Epoch 30, Batch 400: Current Loss = 0.0045\n",
            "Epoch 30, Batch 500: Current Loss = 0.0068\n",
            "Epoch 30, Batch 600: Current Loss = 0.1227\n",
            "Epoch 30, Batch 700: Current Loss = 0.0816\n",
            "Epoch 30, Batch 800: Current Loss = 0.0125\n",
            "Epoch 30, Batch 900: Current Loss = 0.1088\n",
            "Epoch 30, Test Accuracy: 92.56%\n",
            "Epoch 31, Batch 0: Current Loss = 0.0009\n",
            "Epoch 31, Batch 100: Current Loss = 0.0029\n",
            "Epoch 31, Batch 200: Current Loss = 0.0046\n",
            "Epoch 31, Batch 300: Current Loss = 0.0172\n",
            "Epoch 31, Batch 400: Current Loss = 0.0524\n",
            "Epoch 31, Batch 500: Current Loss = 0.0431\n",
            "Epoch 31, Batch 600: Current Loss = 0.0664\n",
            "Epoch 31, Batch 700: Current Loss = 0.0023\n",
            "Epoch 31, Batch 800: Current Loss = 0.0138\n",
            "Epoch 31, Batch 900: Current Loss = 0.0987\n",
            "Epoch 31, Test Accuracy: 92.11%\n",
            "Epoch 32, Batch 0: Current Loss = 0.0268\n",
            "Epoch 32, Batch 100: Current Loss = 0.0069\n",
            "Epoch 32, Batch 200: Current Loss = 0.0333\n",
            "Epoch 32, Batch 300: Current Loss = 0.0466\n",
            "Epoch 32, Batch 400: Current Loss = 0.0437\n",
            "Epoch 32, Batch 500: Current Loss = 0.0472\n",
            "Epoch 32, Batch 600: Current Loss = 0.0248\n",
            "Epoch 32, Batch 700: Current Loss = 0.0742\n",
            "Epoch 32, Batch 800: Current Loss = 0.0069\n",
            "Epoch 32, Batch 900: Current Loss = 0.1460\n",
            "Epoch 32, Test Accuracy: 92.79%\n",
            "Epoch 33, Batch 0: Current Loss = 0.0080\n",
            "Epoch 33, Batch 100: Current Loss = 0.0044\n",
            "Epoch 33, Batch 200: Current Loss = 0.0176\n",
            "Epoch 33, Batch 300: Current Loss = 0.0016\n",
            "Epoch 33, Batch 400: Current Loss = 0.0651\n",
            "Epoch 33, Batch 500: Current Loss = 0.0163\n",
            "Epoch 33, Batch 600: Current Loss = 0.1224\n",
            "Epoch 33, Batch 700: Current Loss = 0.0239\n",
            "Epoch 33, Batch 800: Current Loss = 0.0473\n",
            "Epoch 33, Batch 900: Current Loss = 0.0242\n",
            "Epoch 33, Test Accuracy: 92.79%\n",
            "Epoch 34, Batch 0: Current Loss = 0.0304\n",
            "Epoch 34, Batch 100: Current Loss = 0.0002\n",
            "Epoch 34, Batch 200: Current Loss = 0.0126\n",
            "Epoch 34, Batch 300: Current Loss = 0.0060\n",
            "Epoch 34, Batch 400: Current Loss = 0.0186\n",
            "Epoch 34, Batch 500: Current Loss = 0.0007\n",
            "Epoch 34, Batch 600: Current Loss = 0.0038\n",
            "Epoch 34, Batch 700: Current Loss = 0.0009\n",
            "Epoch 34, Batch 800: Current Loss = 0.0151\n",
            "Epoch 34, Batch 900: Current Loss = 0.0038\n",
            "Epoch 34, Test Accuracy: 92.24%\n",
            "Epoch 35, Batch 0: Current Loss = 0.0140\n",
            "Epoch 35, Batch 100: Current Loss = 0.0013\n",
            "Epoch 35, Batch 200: Current Loss = 0.0014\n",
            "Epoch 35, Batch 300: Current Loss = 0.0008\n",
            "Epoch 35, Batch 400: Current Loss = 0.0252\n",
            "Epoch 35, Batch 500: Current Loss = 0.0758\n",
            "Epoch 35, Batch 600: Current Loss = 0.0066\n",
            "Epoch 35, Batch 700: Current Loss = 0.0043\n",
            "Epoch 35, Batch 800: Current Loss = 0.0982\n",
            "Epoch 35, Batch 900: Current Loss = 0.0602\n",
            "Epoch 35, Test Accuracy: 92.12%\n",
            "Epoch 36, Batch 0: Current Loss = 0.0352\n",
            "Epoch 36, Batch 100: Current Loss = 0.0069\n",
            "Epoch 36, Batch 200: Current Loss = 0.0025\n",
            "Epoch 36, Batch 300: Current Loss = 0.0747\n",
            "Epoch 36, Batch 400: Current Loss = 0.0205\n",
            "Epoch 36, Batch 500: Current Loss = 0.0035\n",
            "Epoch 36, Batch 600: Current Loss = 0.0129\n",
            "Epoch 36, Batch 700: Current Loss = 0.0120\n",
            "Epoch 36, Batch 800: Current Loss = 0.0029\n",
            "Epoch 36, Batch 900: Current Loss = 0.0025\n",
            "Epoch 36, Test Accuracy: 92.90%\n",
            "New best accuracy: 92.90%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 37, Batch 0: Current Loss = 0.0125\n",
            "Epoch 37, Batch 100: Current Loss = 0.0001\n",
            "Epoch 37, Batch 200: Current Loss = 0.0028\n",
            "Epoch 37, Batch 300: Current Loss = 0.0248\n",
            "Epoch 37, Batch 400: Current Loss = 0.0440\n",
            "Epoch 37, Batch 500: Current Loss = 0.0238\n",
            "Epoch 37, Batch 600: Current Loss = 0.0252\n",
            "Epoch 37, Batch 700: Current Loss = 0.0018\n",
            "Epoch 37, Batch 800: Current Loss = 0.0118\n",
            "Epoch 37, Batch 900: Current Loss = 0.0038\n",
            "Epoch 37, Test Accuracy: 92.79%\n",
            "Epoch 38, Batch 0: Current Loss = 0.0005\n",
            "Epoch 38, Batch 100: Current Loss = 0.0043\n",
            "Epoch 38, Batch 200: Current Loss = 0.0100\n",
            "Epoch 38, Batch 300: Current Loss = 0.0005\n",
            "Epoch 38, Batch 400: Current Loss = 0.0030\n",
            "Epoch 38, Batch 500: Current Loss = 0.0308\n",
            "Epoch 38, Batch 600: Current Loss = 0.0082\n",
            "Epoch 38, Batch 700: Current Loss = 0.0078\n",
            "Epoch 38, Batch 800: Current Loss = 0.0320\n",
            "Epoch 38, Batch 900: Current Loss = 0.0122\n",
            "Epoch 38, Test Accuracy: 92.88%\n",
            "Epoch 39, Batch 0: Current Loss = 0.0077\n",
            "Epoch 39, Batch 100: Current Loss = 0.0002\n",
            "Epoch 39, Batch 200: Current Loss = 0.0202\n",
            "Epoch 39, Batch 300: Current Loss = 0.0020\n",
            "Epoch 39, Batch 400: Current Loss = 0.0021\n",
            "Epoch 39, Batch 500: Current Loss = 0.0042\n",
            "Epoch 39, Batch 600: Current Loss = 0.0024\n",
            "Epoch 39, Batch 700: Current Loss = 0.0454\n",
            "Epoch 39, Batch 800: Current Loss = 0.0007\n",
            "Epoch 39, Batch 900: Current Loss = 0.0177\n",
            "Epoch 39, Test Accuracy: 92.24%\n",
            "Epoch 40, Batch 0: Current Loss = 0.0036\n",
            "Epoch 40, Batch 100: Current Loss = 0.0029\n",
            "Epoch 40, Batch 200: Current Loss = 0.0003\n",
            "Epoch 40, Batch 300: Current Loss = 0.0225\n",
            "Epoch 40, Batch 400: Current Loss = 0.0100\n",
            "Epoch 40, Batch 500: Current Loss = 0.0017\n",
            "Epoch 40, Batch 600: Current Loss = 0.0005\n",
            "Epoch 40, Batch 700: Current Loss = 0.0131\n",
            "Epoch 40, Batch 800: Current Loss = 0.0032\n",
            "Epoch 40, Batch 900: Current Loss = 0.0069\n",
            "Epoch 40, Test Accuracy: 92.69%\n",
            "Epoch 41, Batch 0: Current Loss = 0.0089\n",
            "Epoch 41, Batch 100: Current Loss = 0.0035\n",
            "Epoch 41, Batch 200: Current Loss = 0.0023\n",
            "Epoch 41, Batch 300: Current Loss = 0.0036\n",
            "Epoch 41, Batch 400: Current Loss = 0.0023\n",
            "Epoch 41, Batch 500: Current Loss = 0.0053\n",
            "Epoch 41, Batch 600: Current Loss = 0.0044\n",
            "Epoch 41, Batch 700: Current Loss = 0.0468\n",
            "Epoch 41, Batch 800: Current Loss = 0.0717\n",
            "Epoch 41, Batch 900: Current Loss = 0.0076\n",
            "Epoch 41, Test Accuracy: 92.47%\n",
            "Epoch 42, Batch 0: Current Loss = 0.1032\n",
            "Epoch 42, Batch 100: Current Loss = 0.0296\n",
            "Epoch 42, Batch 200: Current Loss = 0.0001\n",
            "Epoch 42, Batch 300: Current Loss = 0.0015\n",
            "Epoch 42, Batch 400: Current Loss = 0.0006\n",
            "Epoch 42, Batch 500: Current Loss = 0.0046\n",
            "Epoch 42, Batch 600: Current Loss = 0.0922\n",
            "Epoch 42, Batch 700: Current Loss = 0.0006\n",
            "Epoch 42, Batch 800: Current Loss = 0.0485\n",
            "Epoch 42, Batch 900: Current Loss = 0.0005\n",
            "Epoch 42, Test Accuracy: 92.39%\n",
            "Epoch 43, Batch 0: Current Loss = 0.0007\n",
            "Epoch 43, Batch 100: Current Loss = 0.0008\n",
            "Epoch 43, Batch 200: Current Loss = 0.0376\n",
            "Epoch 43, Batch 300: Current Loss = 0.0622\n",
            "Epoch 43, Batch 400: Current Loss = 0.0008\n",
            "Epoch 43, Batch 500: Current Loss = 0.0043\n",
            "Epoch 43, Batch 600: Current Loss = 0.0058\n",
            "Epoch 43, Batch 700: Current Loss = 0.0009\n",
            "Epoch 43, Batch 800: Current Loss = 0.0011\n",
            "Epoch 43, Batch 900: Current Loss = 0.0434\n",
            "Epoch 43, Test Accuracy: 92.50%\n",
            "Epoch 44, Batch 0: Current Loss = 0.0042\n",
            "Epoch 44, Batch 100: Current Loss = 0.0082\n",
            "Epoch 44, Batch 200: Current Loss = 0.0007\n",
            "Epoch 44, Batch 300: Current Loss = 0.0106\n",
            "Epoch 44, Batch 400: Current Loss = 0.0047\n",
            "Epoch 44, Batch 500: Current Loss = 0.0050\n",
            "Epoch 44, Batch 600: Current Loss = 0.0085\n",
            "Epoch 44, Batch 700: Current Loss = 0.0047\n",
            "Epoch 44, Batch 800: Current Loss = 0.0000\n",
            "Epoch 44, Batch 900: Current Loss = 0.0641\n",
            "Epoch 44, Test Accuracy: 92.13%\n",
            "Epoch 45, Batch 0: Current Loss = 0.0655\n",
            "Epoch 45, Batch 100: Current Loss = 0.0021\n",
            "Epoch 45, Batch 200: Current Loss = 0.0010\n",
            "Epoch 45, Batch 300: Current Loss = 0.0220\n",
            "Epoch 45, Batch 400: Current Loss = 0.0699\n",
            "Epoch 45, Batch 500: Current Loss = 0.0025\n",
            "Epoch 45, Batch 600: Current Loss = 0.0013\n",
            "Epoch 45, Batch 700: Current Loss = 0.0349\n",
            "Epoch 45, Batch 800: Current Loss = 0.0215\n",
            "Epoch 45, Batch 900: Current Loss = 0.0015\n",
            "Epoch 45, Test Accuracy: 92.79%\n",
            "Epoch 46, Batch 0: Current Loss = 0.0035\n",
            "Epoch 46, Batch 100: Current Loss = 0.0412\n",
            "Epoch 46, Batch 200: Current Loss = 0.0261\n",
            "Epoch 46, Batch 300: Current Loss = 0.0004\n",
            "Epoch 46, Batch 400: Current Loss = 0.0003\n",
            "Epoch 46, Batch 500: Current Loss = 0.0081\n",
            "Epoch 46, Batch 600: Current Loss = 0.0050\n",
            "Epoch 46, Batch 700: Current Loss = 0.0014\n",
            "Epoch 46, Batch 800: Current Loss = 0.0140\n",
            "Epoch 46, Batch 900: Current Loss = 0.0079\n",
            "Epoch 46, Test Accuracy: 92.53%\n",
            "Epoch 47, Batch 0: Current Loss = 0.0819\n",
            "Epoch 47, Batch 100: Current Loss = 0.0132\n",
            "Epoch 47, Batch 200: Current Loss = 0.0414\n",
            "Epoch 47, Batch 300: Current Loss = 0.0013\n",
            "Epoch 47, Batch 400: Current Loss = 0.0036\n",
            "Epoch 47, Batch 500: Current Loss = 0.0006\n",
            "Epoch 47, Batch 600: Current Loss = 0.0783\n",
            "Epoch 47, Batch 700: Current Loss = 0.0126\n",
            "Epoch 47, Batch 800: Current Loss = 0.0021\n",
            "Epoch 47, Batch 900: Current Loss = 0.0360\n",
            "Epoch 47, Test Accuracy: 92.34%\n",
            "Epoch 48, Batch 0: Current Loss = 0.0248\n",
            "Epoch 48, Batch 100: Current Loss = 0.0002\n",
            "Epoch 48, Batch 200: Current Loss = 0.0003\n",
            "Epoch 48, Batch 300: Current Loss = 0.0017\n",
            "Epoch 48, Batch 400: Current Loss = 0.0033\n",
            "Epoch 48, Batch 500: Current Loss = 0.0005\n",
            "Epoch 48, Batch 600: Current Loss = 0.0137\n",
            "Epoch 48, Batch 700: Current Loss = 0.0022\n",
            "Epoch 48, Batch 800: Current Loss = 0.0006\n",
            "Epoch 48, Batch 900: Current Loss = 0.0674\n",
            "Epoch 48, Test Accuracy: 92.36%\n",
            "Epoch 49, Batch 0: Current Loss = 0.0152\n",
            "Epoch 49, Batch 100: Current Loss = 0.0013\n",
            "Epoch 49, Batch 200: Current Loss = 0.0011\n",
            "Epoch 49, Batch 300: Current Loss = 0.0218\n",
            "Epoch 49, Batch 400: Current Loss = 0.0021\n",
            "Epoch 49, Batch 500: Current Loss = 0.0021\n",
            "Epoch 49, Batch 600: Current Loss = 0.0026\n",
            "Epoch 49, Batch 700: Current Loss = 0.0016\n",
            "Epoch 49, Batch 800: Current Loss = 0.0252\n",
            "Epoch 49, Batch 900: Current Loss = 0.0001\n",
            "Epoch 49, Test Accuracy: 92.50%\n",
            "Epoch 50, Batch 0: Current Loss = 0.0012\n",
            "Epoch 50, Batch 100: Current Loss = 0.0743\n",
            "Epoch 50, Batch 200: Current Loss = 0.0063\n",
            "Epoch 50, Batch 300: Current Loss = 0.0047\n",
            "Epoch 50, Batch 400: Current Loss = 0.0017\n",
            "Epoch 50, Batch 500: Current Loss = 0.0004\n",
            "Epoch 50, Batch 600: Current Loss = 0.0186\n",
            "Epoch 50, Batch 700: Current Loss = 0.0039\n",
            "Epoch 50, Batch 800: Current Loss = 0.0009\n",
            "Epoch 50, Batch 900: Current Loss = 0.0081\n",
            "Epoch 50, Test Accuracy: 92.48%\n",
            "Epoch 51, Batch 0: Current Loss = 0.0664\n",
            "Epoch 51, Batch 100: Current Loss = 0.0124\n",
            "Epoch 51, Batch 200: Current Loss = 0.0571\n",
            "Epoch 51, Batch 300: Current Loss = 0.0545\n",
            "Epoch 51, Batch 400: Current Loss = 0.0024\n",
            "Epoch 51, Batch 500: Current Loss = 0.0002\n",
            "Epoch 51, Batch 600: Current Loss = 0.0037\n",
            "Epoch 51, Batch 700: Current Loss = 0.0205\n",
            "Epoch 51, Batch 800: Current Loss = 0.0394\n",
            "Epoch 51, Batch 900: Current Loss = 0.0397\n",
            "Epoch 51, Test Accuracy: 92.58%\n",
            "Epoch 52, Batch 0: Current Loss = 0.0726\n",
            "Epoch 52, Batch 100: Current Loss = 0.0018\n",
            "Epoch 52, Batch 200: Current Loss = 0.0385\n",
            "Epoch 52, Batch 300: Current Loss = 0.0026\n",
            "Epoch 52, Batch 400: Current Loss = 0.0261\n",
            "Epoch 52, Batch 500: Current Loss = 0.0162\n",
            "Epoch 52, Batch 600: Current Loss = 0.0246\n",
            "Epoch 52, Batch 700: Current Loss = 0.0117\n",
            "Epoch 52, Batch 800: Current Loss = 0.0032\n",
            "Epoch 52, Batch 900: Current Loss = 0.0001\n",
            "Epoch 52, Test Accuracy: 92.33%\n",
            "Epoch 53, Batch 0: Current Loss = 0.0266\n",
            "Epoch 53, Batch 100: Current Loss = 0.0002\n",
            "Epoch 53, Batch 200: Current Loss = 0.0035\n",
            "Epoch 53, Batch 300: Current Loss = 0.0293\n",
            "Epoch 53, Batch 400: Current Loss = 0.0080\n",
            "Epoch 53, Batch 500: Current Loss = 0.0011\n",
            "Epoch 53, Batch 600: Current Loss = 0.0261\n",
            "Epoch 53, Batch 700: Current Loss = 0.0246\n",
            "Epoch 53, Batch 800: Current Loss = 0.0004\n",
            "Epoch 53, Batch 900: Current Loss = 0.0058\n",
            "Epoch 53, Test Accuracy: 92.69%\n",
            "Epoch 54, Batch 0: Current Loss = 0.0007\n",
            "Epoch 54, Batch 100: Current Loss = 0.0002\n",
            "Epoch 54, Batch 200: Current Loss = 0.0001\n",
            "Epoch 54, Batch 300: Current Loss = 0.0063\n",
            "Epoch 54, Batch 400: Current Loss = 0.0006\n",
            "Epoch 54, Batch 500: Current Loss = 0.0043\n",
            "Epoch 54, Batch 600: Current Loss = 0.0009\n",
            "Epoch 54, Batch 700: Current Loss = 0.0044\n",
            "Epoch 54, Batch 800: Current Loss = 0.0008\n",
            "Epoch 54, Batch 900: Current Loss = 0.0024\n",
            "Epoch 54, Test Accuracy: 92.14%\n",
            "Epoch 55, Batch 0: Current Loss = 0.0024\n",
            "Epoch 55, Batch 100: Current Loss = 0.0052\n",
            "Epoch 55, Batch 200: Current Loss = 0.0007\n",
            "Epoch 55, Batch 300: Current Loss = 0.0023\n",
            "Epoch 55, Batch 400: Current Loss = 0.0872\n",
            "Epoch 55, Batch 500: Current Loss = 0.0007\n",
            "Epoch 55, Batch 600: Current Loss = 0.0016\n",
            "Epoch 55, Batch 700: Current Loss = 0.0002\n",
            "Epoch 55, Batch 800: Current Loss = 0.0000\n",
            "Epoch 55, Batch 900: Current Loss = 0.0365\n",
            "Epoch 55, Test Accuracy: 92.76%\n",
            "Epoch 56, Batch 0: Current Loss = 0.0012\n",
            "Epoch 56, Batch 100: Current Loss = 0.0491\n",
            "Epoch 56, Batch 200: Current Loss = 0.0016\n",
            "Epoch 56, Batch 300: Current Loss = 0.0181\n",
            "Epoch 56, Batch 400: Current Loss = 0.0568\n",
            "Epoch 56, Batch 500: Current Loss = 0.0060\n",
            "Epoch 56, Batch 600: Current Loss = 0.0056\n",
            "Epoch 56, Batch 700: Current Loss = 0.0205\n",
            "Epoch 56, Batch 800: Current Loss = 0.0217\n",
            "Epoch 56, Batch 900: Current Loss = 0.0240\n",
            "Epoch 56, Test Accuracy: 92.15%\n",
            "Epoch 57, Batch 0: Current Loss = 0.0025\n",
            "Epoch 57, Batch 100: Current Loss = 0.0132\n",
            "Epoch 57, Batch 200: Current Loss = 0.0002\n",
            "Epoch 57, Batch 300: Current Loss = 0.0102\n",
            "Epoch 57, Batch 400: Current Loss = 0.0013\n",
            "Epoch 57, Batch 500: Current Loss = 0.0146\n",
            "Epoch 57, Batch 600: Current Loss = 0.0102\n",
            "Epoch 57, Batch 700: Current Loss = 0.0378\n",
            "Epoch 57, Batch 800: Current Loss = 0.0372\n",
            "Epoch 57, Batch 900: Current Loss = 0.0167\n",
            "Epoch 57, Test Accuracy: 92.36%\n",
            "Epoch 58, Batch 0: Current Loss = 0.0029\n",
            "Epoch 58, Batch 100: Current Loss = 0.1309\n",
            "Epoch 58, Batch 200: Current Loss = 0.0052\n",
            "Epoch 58, Batch 300: Current Loss = 0.0169\n",
            "Epoch 58, Batch 400: Current Loss = 0.0005\n",
            "Epoch 58, Batch 500: Current Loss = 0.0002\n",
            "Epoch 58, Batch 600: Current Loss = 0.0519\n",
            "Epoch 58, Batch 700: Current Loss = 0.0237\n",
            "Epoch 58, Batch 800: Current Loss = 0.0096\n",
            "Epoch 58, Batch 900: Current Loss = 0.0775\n",
            "Epoch 58, Test Accuracy: 92.76%\n",
            "Epoch 59, Batch 0: Current Loss = 0.0028\n",
            "Epoch 59, Batch 100: Current Loss = 0.0000\n",
            "Epoch 59, Batch 200: Current Loss = 0.1463\n",
            "Epoch 59, Batch 300: Current Loss = 0.0003\n",
            "Epoch 59, Batch 400: Current Loss = 0.0063\n",
            "Epoch 59, Batch 500: Current Loss = 0.0158\n",
            "Epoch 59, Batch 600: Current Loss = 0.0005\n",
            "Epoch 59, Batch 700: Current Loss = 0.0004\n",
            "Epoch 59, Batch 800: Current Loss = 0.0028\n",
            "Epoch 59, Batch 900: Current Loss = 0.0022\n",
            "Epoch 59, Test Accuracy: 92.71%\n",
            "Epoch 60, Batch 0: Current Loss = 0.0041\n",
            "Epoch 60, Batch 100: Current Loss = 0.0366\n",
            "Epoch 60, Batch 200: Current Loss = 0.0004\n",
            "Epoch 60, Batch 300: Current Loss = 0.0072\n",
            "Epoch 60, Batch 400: Current Loss = 0.0043\n",
            "Epoch 60, Batch 500: Current Loss = 0.0290\n",
            "Epoch 60, Batch 600: Current Loss = 0.0057\n",
            "Epoch 60, Batch 700: Current Loss = 0.0221\n",
            "Epoch 60, Batch 800: Current Loss = 0.1010\n",
            "Epoch 60, Batch 900: Current Loss = 0.0379\n",
            "Epoch 60, Test Accuracy: 92.75%\n",
            "Epoch 61, Batch 0: Current Loss = 0.0000\n",
            "Epoch 61, Batch 100: Current Loss = 0.0013\n",
            "Epoch 61, Batch 200: Current Loss = 0.0042\n",
            "Epoch 61, Batch 300: Current Loss = 0.0000\n",
            "Epoch 61, Batch 400: Current Loss = 0.0051\n",
            "Epoch 61, Batch 500: Current Loss = 0.0092\n",
            "Epoch 61, Batch 600: Current Loss = 0.0065\n",
            "Epoch 61, Batch 700: Current Loss = 0.0015\n",
            "Epoch 61, Batch 800: Current Loss = 0.0011\n",
            "Epoch 61, Batch 900: Current Loss = 0.0743\n",
            "Epoch 61, Test Accuracy: 92.67%\n",
            "Epoch 62, Batch 0: Current Loss = 0.0039\n",
            "Epoch 62, Batch 100: Current Loss = 0.0031\n",
            "Epoch 62, Batch 200: Current Loss = 0.0011\n",
            "Epoch 62, Batch 300: Current Loss = 0.0743\n",
            "Epoch 62, Batch 400: Current Loss = 0.0416\n",
            "Epoch 62, Batch 500: Current Loss = 0.0141\n",
            "Epoch 62, Batch 600: Current Loss = 0.0003\n",
            "Epoch 62, Batch 700: Current Loss = 0.0049\n",
            "Epoch 62, Batch 800: Current Loss = 0.0002\n",
            "Epoch 62, Batch 900: Current Loss = 0.1198\n",
            "Epoch 62, Test Accuracy: 92.78%\n",
            "Epoch 63, Batch 0: Current Loss = 0.0108\n",
            "Epoch 63, Batch 100: Current Loss = 0.0005\n",
            "Epoch 63, Batch 200: Current Loss = 0.0003\n",
            "Epoch 63, Batch 300: Current Loss = 0.1351\n",
            "Epoch 63, Batch 400: Current Loss = 0.0014\n",
            "Epoch 63, Batch 500: Current Loss = 0.0260\n",
            "Epoch 63, Batch 600: Current Loss = 0.0012\n",
            "Epoch 63, Batch 700: Current Loss = 0.0000\n",
            "Epoch 63, Batch 800: Current Loss = 0.0028\n",
            "Epoch 63, Batch 900: Current Loss = 0.0089\n",
            "Epoch 63, Test Accuracy: 92.24%\n",
            "Epoch 64, Batch 0: Current Loss = 0.0459\n",
            "Epoch 64, Batch 100: Current Loss = 0.0012\n",
            "Epoch 64, Batch 200: Current Loss = 0.0000\n",
            "Epoch 64, Batch 300: Current Loss = 0.0042\n",
            "Epoch 64, Batch 400: Current Loss = 0.0006\n",
            "Epoch 64, Batch 500: Current Loss = 0.0268\n",
            "Epoch 64, Batch 600: Current Loss = 0.0037\n",
            "Epoch 64, Batch 700: Current Loss = 0.0002\n",
            "Epoch 64, Batch 800: Current Loss = 0.0214\n",
            "Epoch 64, Batch 900: Current Loss = 0.0138\n",
            "Epoch 64, Test Accuracy: 92.54%\n",
            "Epoch 65, Batch 0: Current Loss = 0.0000\n",
            "Epoch 65, Batch 100: Current Loss = 0.0014\n",
            "Epoch 65, Batch 200: Current Loss = 0.0641\n",
            "Epoch 65, Batch 300: Current Loss = 0.0000\n",
            "Epoch 65, Batch 400: Current Loss = 0.0117\n",
            "Epoch 65, Batch 500: Current Loss = 0.0011\n",
            "Epoch 65, Batch 600: Current Loss = 0.0053\n",
            "Epoch 65, Batch 700: Current Loss = 0.0014\n",
            "Epoch 65, Batch 800: Current Loss = 0.0013\n",
            "Epoch 65, Batch 900: Current Loss = 0.0248\n",
            "Epoch 65, Test Accuracy: 92.55%\n",
            "Epoch 66, Batch 0: Current Loss = 0.0023\n",
            "Epoch 66, Batch 100: Current Loss = 0.0070\n",
            "Epoch 66, Batch 200: Current Loss = 0.0003\n",
            "Epoch 66, Batch 300: Current Loss = 0.0050\n",
            "Epoch 66, Batch 400: Current Loss = 0.0052\n",
            "Epoch 66, Batch 500: Current Loss = 0.0000\n",
            "Epoch 66, Batch 600: Current Loss = 0.0051\n",
            "Epoch 66, Batch 700: Current Loss = 0.0006\n",
            "Epoch 66, Batch 800: Current Loss = 0.0002\n",
            "Epoch 66, Batch 900: Current Loss = 0.0092\n",
            "Epoch 66, Test Accuracy: 92.45%\n",
            "Epoch 67, Batch 0: Current Loss = 0.0001\n",
            "Epoch 67, Batch 100: Current Loss = 0.0117\n",
            "Epoch 67, Batch 200: Current Loss = 0.0550\n",
            "Epoch 67, Batch 300: Current Loss = 0.0001\n",
            "Epoch 67, Batch 400: Current Loss = 0.0021\n",
            "Epoch 67, Batch 500: Current Loss = 0.0986\n",
            "Epoch 67, Batch 600: Current Loss = 0.0053\n",
            "Epoch 67, Batch 700: Current Loss = 0.0090\n",
            "Epoch 67, Batch 800: Current Loss = 0.0046\n",
            "Epoch 67, Batch 900: Current Loss = 0.0029\n",
            "Epoch 67, Test Accuracy: 92.83%\n",
            "Epoch 68, Batch 0: Current Loss = 0.0010\n",
            "Epoch 68, Batch 100: Current Loss = 0.0000\n",
            "Epoch 68, Batch 200: Current Loss = 0.0003\n",
            "Epoch 68, Batch 300: Current Loss = 0.0011\n",
            "Epoch 68, Batch 400: Current Loss = 0.0054\n",
            "Epoch 68, Batch 500: Current Loss = 0.0034\n",
            "Epoch 68, Batch 600: Current Loss = 0.0864\n",
            "Epoch 68, Batch 700: Current Loss = 0.0288\n",
            "Epoch 68, Batch 800: Current Loss = 0.0000\n",
            "Epoch 68, Batch 900: Current Loss = 0.0381\n",
            "Epoch 68, Test Accuracy: 92.94%\n",
            "New best accuracy: 92.94%\n",
            "Best model saved as best_model.pt\n",
            "Epoch 69, Batch 0: Current Loss = 0.0135\n",
            "Epoch 69, Batch 100: Current Loss = 0.0091\n",
            "Epoch 69, Batch 200: Current Loss = 0.0006\n",
            "Epoch 69, Batch 300: Current Loss = 0.0265\n",
            "Epoch 69, Batch 400: Current Loss = 0.0061\n",
            "Epoch 69, Batch 500: Current Loss = 0.0222\n",
            "Epoch 69, Batch 600: Current Loss = 0.0019\n",
            "Epoch 69, Batch 700: Current Loss = 0.0002\n",
            "Epoch 69, Batch 800: Current Loss = 0.0009\n",
            "Epoch 69, Batch 900: Current Loss = 0.0002\n",
            "Epoch 69, Test Accuracy: 92.67%\n",
            "Epoch 70, Batch 0: Current Loss = 0.0019\n",
            "Epoch 70, Batch 100: Current Loss = 0.0119\n",
            "Epoch 70, Batch 200: Current Loss = 0.0000\n",
            "Epoch 70, Batch 300: Current Loss = 0.0028\n",
            "Epoch 70, Batch 400: Current Loss = 0.1138\n",
            "Epoch 70, Batch 500: Current Loss = 0.0279\n",
            "Epoch 70, Batch 600: Current Loss = 0.0008\n",
            "Epoch 70, Batch 700: Current Loss = 0.0004\n",
            "Epoch 70, Batch 800: Current Loss = 0.0025\n",
            "Epoch 70, Batch 900: Current Loss = 0.0007\n",
            "Epoch 70, Test Accuracy: 91.91%\n",
            "Epoch 71, Batch 0: Current Loss = 0.0009\n",
            "Epoch 71, Batch 100: Current Loss = 0.0002\n",
            "Epoch 71, Batch 200: Current Loss = 0.0169\n",
            "Epoch 71, Batch 300: Current Loss = 0.0019\n",
            "Epoch 71, Batch 400: Current Loss = 0.0052\n",
            "Epoch 71, Batch 500: Current Loss = 0.0003\n",
            "Epoch 71, Batch 600: Current Loss = 0.1107\n",
            "Epoch 71, Batch 700: Current Loss = 0.0030\n",
            "Epoch 71, Batch 800: Current Loss = 0.0252\n",
            "Epoch 71, Batch 900: Current Loss = 0.0023\n",
            "Epoch 71, Test Accuracy: 92.62%\n",
            "Epoch 72, Batch 0: Current Loss = 0.0030\n",
            "Epoch 72, Batch 100: Current Loss = 0.0172\n",
            "Epoch 72, Batch 200: Current Loss = 0.0004\n",
            "Epoch 72, Batch 300: Current Loss = 0.0015\n",
            "Epoch 72, Batch 400: Current Loss = 0.0184\n",
            "Epoch 72, Batch 500: Current Loss = 0.0441\n",
            "Epoch 72, Batch 600: Current Loss = 0.0005\n",
            "Epoch 72, Batch 700: Current Loss = 0.0016\n",
            "Epoch 72, Batch 800: Current Loss = 0.0002\n",
            "Epoch 72, Batch 900: Current Loss = 0.0010\n",
            "Epoch 72, Test Accuracy: 92.42%\n",
            "Epoch 73, Batch 0: Current Loss = 0.0065\n",
            "Epoch 73, Batch 100: Current Loss = 0.0096\n",
            "Epoch 73, Batch 200: Current Loss = 0.0001\n",
            "Epoch 73, Batch 300: Current Loss = 0.0025\n",
            "Epoch 73, Batch 400: Current Loss = 0.0003\n",
            "Epoch 73, Batch 500: Current Loss = 0.0000\n",
            "Epoch 73, Batch 600: Current Loss = 0.0006\n",
            "Epoch 73, Batch 700: Current Loss = 0.0001\n",
            "Epoch 73, Batch 800: Current Loss = 0.0021\n",
            "Epoch 73, Batch 900: Current Loss = 0.0135\n",
            "Epoch 73, Test Accuracy: 92.65%\n",
            "Epoch 74, Batch 0: Current Loss = 0.0348\n",
            "Epoch 74, Batch 100: Current Loss = 0.0000\n",
            "Epoch 74, Batch 200: Current Loss = 0.0000\n",
            "Epoch 74, Batch 300: Current Loss = 0.0008\n",
            "Epoch 74, Batch 400: Current Loss = 0.0258\n",
            "Epoch 74, Batch 500: Current Loss = 0.0744\n",
            "Epoch 74, Batch 600: Current Loss = 0.0001\n",
            "Epoch 74, Batch 700: Current Loss = 0.0377\n",
            "Epoch 74, Batch 800: Current Loss = 0.0002\n",
            "Epoch 74, Batch 900: Current Loss = 0.0047\n",
            "Epoch 74, Test Accuracy: 92.55%\n",
            "Epoch 75, Batch 0: Current Loss = 0.0033\n",
            "Epoch 75, Batch 100: Current Loss = 0.0019\n",
            "Epoch 75, Batch 200: Current Loss = 0.0004\n",
            "Epoch 75, Batch 300: Current Loss = 0.0008\n",
            "Epoch 75, Batch 400: Current Loss = 0.0197\n",
            "Epoch 75, Batch 500: Current Loss = 0.0029\n",
            "Epoch 75, Batch 600: Current Loss = 0.0329\n",
            "Epoch 75, Batch 700: Current Loss = 0.0033\n",
            "Epoch 75, Batch 800: Current Loss = 0.0017\n",
            "Epoch 75, Batch 900: Current Loss = 0.0003\n",
            "Epoch 75, Test Accuracy: 92.83%\n",
            "Epoch 76, Batch 0: Current Loss = 0.0004\n",
            "Epoch 76, Batch 100: Current Loss = 0.0001\n",
            "Epoch 76, Batch 200: Current Loss = 0.0065\n",
            "Epoch 76, Batch 300: Current Loss = 0.0002\n",
            "Epoch 76, Batch 400: Current Loss = 0.0009\n",
            "Epoch 76, Batch 500: Current Loss = 0.0005\n",
            "Epoch 76, Batch 600: Current Loss = 0.0088\n",
            "Epoch 76, Batch 700: Current Loss = 0.0183\n",
            "Epoch 76, Batch 800: Current Loss = 0.0101\n",
            "Epoch 76, Batch 900: Current Loss = 0.0001\n",
            "Epoch 76, Test Accuracy: 92.52%\n",
            "Epoch 77, Batch 0: Current Loss = 0.0016\n",
            "Epoch 77, Batch 100: Current Loss = 0.0004\n",
            "Epoch 77, Batch 200: Current Loss = 0.0019\n",
            "Epoch 77, Batch 300: Current Loss = 0.0783\n",
            "Epoch 77, Batch 400: Current Loss = 0.0045\n",
            "Epoch 77, Batch 500: Current Loss = 0.0007\n",
            "Epoch 77, Batch 600: Current Loss = 0.0021\n",
            "Epoch 77, Batch 700: Current Loss = 0.0012\n",
            "Epoch 77, Batch 800: Current Loss = 0.0403\n",
            "Epoch 77, Batch 900: Current Loss = 0.0008\n",
            "Epoch 77, Test Accuracy: 92.47%\n",
            "Epoch 78, Batch 0: Current Loss = 0.0022\n",
            "Epoch 78, Batch 100: Current Loss = 0.0126\n",
            "Epoch 78, Batch 200: Current Loss = 0.0029\n",
            "Epoch 78, Batch 300: Current Loss = 0.0020\n",
            "Epoch 78, Batch 400: Current Loss = 0.0006\n",
            "Epoch 78, Batch 500: Current Loss = 0.0643\n",
            "Epoch 78, Batch 600: Current Loss = 0.0441\n",
            "Epoch 78, Batch 700: Current Loss = 0.0395\n",
            "Epoch 78, Batch 800: Current Loss = 0.0400\n",
            "Epoch 78, Batch 900: Current Loss = 0.0582\n",
            "Epoch 78, Test Accuracy: 92.50%\n",
            "Epoch 79, Batch 0: Current Loss = 0.0000\n",
            "Epoch 79, Batch 100: Current Loss = 0.0105\n",
            "Epoch 79, Batch 200: Current Loss = 0.0056\n",
            "Epoch 79, Batch 300: Current Loss = 0.0165\n",
            "Epoch 79, Batch 400: Current Loss = 0.0002\n",
            "Epoch 79, Batch 500: Current Loss = 0.0021\n",
            "Epoch 79, Batch 600: Current Loss = 0.0002\n",
            "Epoch 79, Batch 700: Current Loss = 0.0023\n",
            "Epoch 79, Batch 800: Current Loss = 0.0007\n",
            "Epoch 79, Batch 900: Current Loss = 0.0002\n",
            "Epoch 79, Test Accuracy: 92.58%\n",
            "Epoch 80, Batch 0: Current Loss = 0.0002\n",
            "Epoch 80, Batch 100: Current Loss = 0.0102\n",
            "Epoch 80, Batch 200: Current Loss = 0.0081\n",
            "Epoch 80, Batch 300: Current Loss = 0.0040\n",
            "Epoch 80, Batch 400: Current Loss = 0.0037\n",
            "Epoch 80, Batch 500: Current Loss = 0.0041\n",
            "Epoch 80, Batch 600: Current Loss = 0.0008\n",
            "Epoch 80, Batch 700: Current Loss = 0.0167\n",
            "Epoch 80, Batch 800: Current Loss = 0.0045\n",
            "Epoch 80, Batch 900: Current Loss = 0.0006\n",
            "Epoch 80, Test Accuracy: 92.84%\n",
            "Epoch 81, Batch 0: Current Loss = 0.0020\n",
            "Epoch 81, Batch 100: Current Loss = 0.0011\n",
            "Epoch 81, Batch 200: Current Loss = 0.0554\n",
            "Epoch 81, Batch 300: Current Loss = 0.0023\n",
            "Epoch 81, Batch 400: Current Loss = 0.0091\n",
            "Epoch 81, Batch 500: Current Loss = 0.0019\n",
            "Epoch 81, Batch 600: Current Loss = 0.0054\n",
            "Epoch 81, Batch 700: Current Loss = 0.0042\n",
            "Epoch 81, Batch 800: Current Loss = 0.0039\n",
            "Epoch 81, Batch 900: Current Loss = 0.0592\n",
            "Epoch 81, Test Accuracy: 92.80%\n",
            "Epoch 82, Batch 0: Current Loss = 0.0002\n",
            "Epoch 82, Batch 100: Current Loss = 0.0009\n",
            "Epoch 82, Batch 200: Current Loss = 0.0005\n",
            "Epoch 82, Batch 300: Current Loss = 0.0001\n",
            "Epoch 82, Batch 400: Current Loss = 0.0022\n",
            "Epoch 82, Batch 500: Current Loss = 0.0002\n",
            "Epoch 82, Batch 600: Current Loss = 0.0013\n",
            "Epoch 82, Batch 700: Current Loss = 0.0004\n",
            "Epoch 82, Batch 800: Current Loss = 0.0005\n",
            "Epoch 82, Batch 900: Current Loss = 0.0059\n",
            "Epoch 82, Test Accuracy: 92.67%\n",
            "Epoch 83, Batch 0: Current Loss = 0.0041\n",
            "Epoch 83, Batch 100: Current Loss = 0.0132\n",
            "Epoch 83, Batch 200: Current Loss = 0.0005\n",
            "Epoch 83, Batch 300: Current Loss = 0.0008\n",
            "Epoch 83, Batch 400: Current Loss = 0.0000\n",
            "Epoch 83, Batch 500: Current Loss = 0.0641\n",
            "Epoch 83, Batch 600: Current Loss = 0.0000\n",
            "Epoch 83, Batch 700: Current Loss = 0.0000\n",
            "Epoch 83, Batch 800: Current Loss = 0.0014\n",
            "Epoch 83, Batch 900: Current Loss = 0.0004\n",
            "Epoch 83, Test Accuracy: 92.18%\n",
            "Epoch 84, Batch 0: Current Loss = 0.0005\n",
            "Epoch 84, Batch 100: Current Loss = 0.0002\n",
            "Epoch 84, Batch 200: Current Loss = 0.0013\n",
            "Epoch 84, Batch 300: Current Loss = 0.0000\n",
            "Epoch 84, Batch 400: Current Loss = 0.0012\n",
            "Epoch 84, Batch 500: Current Loss = 0.0011\n",
            "Epoch 84, Batch 600: Current Loss = 0.0982\n",
            "Epoch 84, Batch 700: Current Loss = 0.0013\n",
            "Epoch 84, Batch 800: Current Loss = 0.0000\n",
            "Epoch 84, Batch 900: Current Loss = 0.0196\n",
            "Epoch 84, Test Accuracy: 92.61%\n",
            "\n",
            "Training complete!\n",
            "Highest accuracy achieved during training: 92.94%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyIDIl9EjmDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xryjY-UpjmfJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}